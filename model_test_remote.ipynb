{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\togar\\AppData\\Local\\Temp\\ipykernel_24020\\670950859.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import *\n",
    "import gc\n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import ICA, corrmap, create_ecg_epochs, create_eog_epochs\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Filtering functions\n",
    "def butter_bandpass(lowcut, highcut, fs, order=6):\n",
    "  return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=6):\n",
    "  b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "  y = lfilter(b, a, data)\n",
    "  return y\n",
    "def calcsnr(prefilter, filtered):\n",
    "  filteredsum = 0\n",
    "  denomsum = 0\n",
    "  for i in range(len(prefilter)):\n",
    "    filteredsum = filteredsum+filtered[i]*filtered[i]\n",
    "    denomsum = denomsum+ (filtered[i]-prefilter[i])*(filtered[i]-prefilter[i])\n",
    "  return 10*math.log10(filteredsum/denomsum)\n",
    "\n",
    "# Custom dataset object\n",
    "class EEGDataset(Dataset):\n",
    "  def __init__(self, eeglist, labels, transform=None, target_transform=None):\n",
    "    self.labels = torch.from_numpy(np.array(labels))\n",
    "    self.labels = self.labels.to(torch.float32)\n",
    "    self.eeglist = eeglist\n",
    "    self.transform = transform\n",
    "    self.target_transform = target_transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    label = self.labels[idx]\n",
    "    raw = self.eeglist[idx]\n",
    "    eeg = torch.from_numpy(raw.get_data())\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    if self.target_transform:\n",
    "      label = self.target_transform(label)\n",
    "    return eeg, label\n",
    "\n",
    "# Collect Raw objects from MNE in Python lists\n",
    "data_list = {\"raw\":[], \"preprocessed\":[], \"manual_preprocess\":[], \"rawsample\": [], \"preprocessedsample\":[], \"manual_preprocesssample\":[]}\n",
    "labels = []\n",
    "\n",
    "# Get subject information\n",
    "readtsv = pd.read_csv('participants.tsv', sep = '\\t')\n",
    "\n",
    "# Channel names, taken from OpenNeuro\n",
    "channel_names = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']\n",
    "\n",
    "# Parse in .set files\n",
    "for i in range(1,89):\n",
    "\n",
    "  filteredpath = r\"C:\\Users\\togar\\Documents\\UofT\\Spring Term 2024\\APS360 - Fundamentals of Deep Learning\\EEG-Alzheimer-Detection\\OpenNeuro Preprocessed\\sub-%s\\eeg\"%(str(i).zfill(3))\n",
    "  filteredfile = glob.glob(os.path.join(filteredpath, '*.set'))\n",
    "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
    "\n",
    "  rawpath = r\"C:\\Users\\togar\\Documents\\UofT\\Spring Term 2024\\APS360 - Fundamentals of Deep Learning\\EEG-Alzheimer-Detection\\Raw Data\\sub-%s\\eeg\"%(str(i).zfill(3))\n",
    "  file = glob.glob(os.path.join(rawpath, '*.set'))\n",
    "  raw = mne.io.read_raw_eeglab(file[0], preload = True)\n",
    "\n",
    "  # Update data lists\n",
    "  data_list['raw'].append(raw)\n",
    "  data_list['preprocessed'].append(filtered)\n",
    "\n",
    "  label = readtsv['Group'][i-1]\n",
    "  # Change labels to onehot encodings\n",
    "  if label == 'A':\n",
    "    labels.append([0,0,1])\n",
    "  elif label == 'F':\n",
    "    labels.append([0,1,0])\n",
    "  elif label == 'C':\n",
    "    labels.append([1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne_icalabel import label_components\n",
    "exclusion = ['line noise', 'heartbeat', 'eye blink']\n",
    "\n",
    "def manual_process(raw, plotting = True):\n",
    "    freq_low = 0.5\n",
    "    freq_high = 45\n",
    "    iirparams = dict(order = 4, ftype = 'butter')\n",
    "\n",
    "    raw.filter(freq_low, freq_high, method = 'iir', iir_params = iirparams)\n",
    "\n",
    "    # Create ICA object and fit it to the data\n",
    "    ica = ICA(n_components=19, random_state=97, verbose = False)\n",
    "    ica.fit(raw)\n",
    "\n",
    "    # Plot ICA components to identify artifacts\n",
    "    icalabels = label_components(raw, ica, method = 'iclabel')\n",
    "    if plotting == True:\n",
    "        ica.plot_components()\n",
    "        picks = list(range(0,18))\n",
    "        ica.plot_properties(raw, picks=picks)\n",
    "        print(icalabels)\n",
    "    ica.exclude = []\n",
    "    for i, label in enumerate(icalabels):\n",
    "        if label in exclusion:\n",
    "            ica.exclude.append(i)\n",
    "    ica.apply(raw)\n",
    "            \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output \n",
    "i = 0\n",
    "for subject in data_list['raw']:\n",
    "    raw = subject.copy().load_data()\n",
    "    data_list['manual_preprocess'].append(manual_process(raw, plotting = False))\n",
    "    clear_output()\n",
    "    i+=1\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "totals = [485.5, 276.5, 402]\n",
    "trainlist, vallist, testlist, trainlabels, vallabels, testlabels = [],[],[],[],[],[]\n",
    "labelonehot = [[0,0,1], [0,1,0], [1,0,0]]\n",
    "#make sure enough of each group in each partition of data\n",
    "for x, label in enumerate(labelonehot):\n",
    "  count = 0\n",
    "  for i in range (len(labels)):\n",
    "    if labels[i] == label:\n",
    "      m = 0\n",
    "      # print(len(n.get_data()[0]))\n",
    "      while 15000*(m+1) < len(data_list['raw'][i].copy().get_data()[0]):\n",
    "        if totals[x]*2-count>120:\n",
    "          n = data_list['raw'][i].copy()\n",
    "          trainlist.append(n.crop(m*30,(m+1)*30))\n",
    "          trainlabels.append(labels[i])\n",
    "        if totals[x]*2-count>40:\n",
    "          n = data_list['raw'][i].copy()\n",
    "          vallist.append(n.crop(m*30,(m+1)*30))\n",
    "          vallabels.append(labels[i])\n",
    "        else:\n",
    "          n = data_list['raw'][i].copy()\n",
    "          testlist.append(n.crop(m*30, (m+1)*30))\n",
    "          testlabels.append(labels[i])\n",
    "        count = count + 1\n",
    "        m = m+1\n",
    "\n",
    "\n",
    "trainset = EEGDataset(trainlist, trainlabels)\n",
    "valset = EEGDataset(vallist, vallabels)\n",
    "testset = EEGDataset(testlist, testlabels)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = 127, shuffle = True)\n",
    "valloader = DataLoader(valset, batch_size = 127, shuffle = True)\n",
    "testloader = DataLoader(testset, batch_size = 127, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CNN_EEG_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EEG_Classifier, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, 25, 2) \n",
    "        \n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(25)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(4, 4)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(25, 30, 2) \n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(30)\n",
    "        self.fc1 = nn.Linear(28110, 256)\n",
    "        self.fc2 = nn.Linear(256, 3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = F.relu(self.fc1(outconv2))\n",
    "        # print(outfc1.shape)\n",
    "\n",
    "        outfc2 = self.fc2(outfc1)\n",
    "        # print(outfc2.shape)\n",
    "\n",
    "        out = F.softmax(outfc2, dim = 1)\n",
    "        print(out.shape)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CNN_EEG_Classifier_lstm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EEG_Classifier_lstm, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, 25, 2) \n",
    "        \n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(25)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(4, 4)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(25, 30, 2) \n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(30)\n",
    "\n",
    "        self.hidden_size = 100\n",
    "        self.lstm = nn.LSTM(30, self.hidden_size, 1, batch_first = True)\n",
    "\n",
    "        self.fc1 = nn.Linear(28110, 256)\n",
    "        self.fc2 = nn.Linear(256, 3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        # print(x.shape, h0.shape, c0.shape)\n",
    "        outlstm = outconv2.permute(0, 2, 1)\n",
    "        outlstm, _ = self.lstm(outlstm, (h0, c0))\n",
    "        outlstm = outlstm[:, -1, :]\n",
    "        outlstm = outlstm.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = F.relu(self.fc1(outlstm))\n",
    "\n",
    "        # print(outfc1.shape)\n",
    "\n",
    "        outfc2 = self.fc2(outfc1)\n",
    "        # print(outfc2.shape)\n",
    "\n",
    "        out = F.softmax(outfc2, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CNN_EEG_Classifier_dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EEG_Classifier_dropout, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, 25, 2) \n",
    "        \n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(25)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(4, 4)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(25, 30, 2) \n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(30)\n",
    "\n",
    "        self.fc1 = nn.Linear(28110, 10000)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(10000, 1000)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = self.dropout1(F.relu(self.fc1(outconv2)))\n",
    "\n",
    "        # print(outfc1.shape)\n",
    "\n",
    "        outfc2 = self.dropout2(self.fc2(outfc1))\n",
    "        # print(outfc2.shape)\n",
    "\n",
    "        outfc3 = self.dropout3(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CNN_EEG_Classifier_linear1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EEG_Classifier_linear1, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, 25, 2) \n",
    "        \n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(25)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(4, 4)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(25, 30, 2) \n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(30)\n",
    "\n",
    "        self.fc1 = nn.Linear(28110, 10000)\n",
    "        self.fc2 = nn.Linear(10000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv2)))\n",
    "\n",
    "        # print(outfc1.shape)\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "        # print(outfc2.shape)\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CNN_EEG_Classifier_linear2(nn.Module):\n",
    "    def __init__(self, conv1_kernel_size = 2, conv2_kernel_size = 2, conv1_size = 25, conv2_size = 30, pool_kernel = 2, pool_stride = 2, conv1_stride = 1, conv2_stride = 1):\n",
    "        \"\"\"Average Pool, Pool size 2\"\"\"\n",
    "        super(CNN_EEG_Classifier_linear2, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, conv1_size, conv1_kernel_size) \n",
    "        size1 = ((15001-conv1_kernel_size)/conv1_stride) + 1\n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(conv1_size)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.AvgPool1d(pool_kernel, pool_stride)\n",
    "        size1_pool = ((size1 - pool_kernel)/pool_stride) + 1\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv1_size, conv2_size, conv2_kernel_size) \n",
    "        size2 = ((size1_pool-conv2_kernel_size)/conv2_stride) + 1\n",
    "        size2_pool = ((size2 - pool_kernel)//pool_stride) + 1\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(conv2_size)\n",
    "\n",
    "        size1_flatten = size2_pool*conv2_size\n",
    "        linear1_size = int(size1_flatten)\n",
    "\n",
    "        self.fc1 = nn.Linear(linear1_size, 10000)\n",
    "        self.fc2 = nn.Linear(10000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "        # print(outconv2.shape)\n",
    "        outfc1 = (F.relu(self.fc1(outconv2)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_EEG_Classifier_linear3(nn.Module):\n",
    "    def __init__(self, conv1_kernel_size = 2, conv2_kernel_size = 2, conv1_size = 25, conv2_size = 30, pool_kernel = 2, pool_stride = 2, conv1_stride = 1, conv2_stride = 1):\n",
    "        \"\"\"Max Pool, Pool size 2\"\"\"\n",
    "        super(CNN_EEG_Classifier_linear3, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, conv1_size, conv1_kernel_size) \n",
    "        size1 = ((15001-conv1_kernel_size)/conv1_stride) + 1\n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(conv1_size)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(pool_kernel, pool_stride)\n",
    "        size1_pool = ((size1 - pool_kernel)/pool_stride) + 1\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv1_size, conv2_size, conv2_kernel_size) \n",
    "        size2 = ((size1_pool-conv2_kernel_size)/conv2_stride) + 1\n",
    "        size2_pool = ((size2 - pool_kernel)//pool_stride) + 1\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(conv2_size)\n",
    "\n",
    "        size1_flatten = size2_pool*conv2_size\n",
    "        linear1_size = int(size1_flatten)\n",
    "\n",
    "        self.fc1 = nn.Linear(linear1_size, 10000)\n",
    "        self.fc2 = nn.Linear(10000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "        # print(outconv2.shape)\n",
    "        outfc1 = (F.relu(self.fc1(outconv2)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_LSTM_EEG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM_EEG, self).__init__()\n",
    "        # This is taking in 64 channels from what I understand, we could change it to 19\n",
    "        self.conv1 = nn.Conv1d(19, 64, kernel_size = 3, stride = 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size = 3, stride = 1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        # self.conv1 = nn.Conv2d(1, 64, kernel_size = (1,3), stride = 1)\n",
    "        # self.conv2 = nn.Conv2d(64, 64, kernel_size = (1, 3), stride = 1)\n",
    "        # print(\"SHAPE =\", self.conv1.weight.shape)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.pool = nn.MaxPool1d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.flatten = nn.Flatten() # Rad removed this line\n",
    "        self.hidden_size = 100\n",
    "        self.lstm = nn.LSTM(64, self.hidden_size, 1, batch_first = True)\n",
    "        \n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(100, 100)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.dropout4 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        # print(x.shape)\n",
    "        x = (self.pool(self.dropout1(F.relu(self.bn1(self.conv2(x))))))\n",
    "        # print(x.shape)\n",
    "        # x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        # print(x.shape, h0.shape, c0.shape)\n",
    "        print(x.shape)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        print(x.shape)\n",
    "        x = self.dropout2(x[:, -1, :])\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(F.relu(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc3(F.sigmoid(x))\n",
    "        print(x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CNN_EEG_Classifier_linear_cnn_extra(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"MORE CNNs, MORE LAYERS, MORE POWER\"\"\"\n",
    "        super(CNN_EEG_Classifier_linear_cnn_extra, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35, 40, 50]\n",
    "        conv_stride = [1, 1, 1, 1, 1]\n",
    "        conv_kernel_size = [2, 2, 2, 2, 2]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = 4\n",
    "        pool_stride = 4\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.conv4 = nn.Conv1d(conv_size[2], conv_size[3], conv_kernel_size[3], conv_stride[3])\n",
    "        self.bn4 = nn.BatchNorm1d(conv_size[3])\n",
    "        self.conv5 = nn.Conv1d(conv_size[3], conv_size[4], conv_kernel_size[4], conv_stride[4])\n",
    "        self.bn5 = nn.BatchNorm1d(conv_size[4])\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(pool_kernel, pool_stride)\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel)//pool_stride) + 1  \n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        outconv3 = self.pool(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        outconv4 = self.pool(F.relu(self.bn4(self.conv4(outconv3))))\n",
    "        outconv5 = self.pool(F.relu(self.bn5(self.conv5(outconv4))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv5 = outconv5.view(batch_size, -1)\n",
    "        # print(outconv2.shape)\n",
    "        outfc1 = (F.relu(self.fc1(outconv2)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNN_EEG_Classifier_linear_cnn_extra_pool_less(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"MORE CNNs, MORE LAYERS, MORE POWER\"\"\"\n",
    "        super(CNN_EEG_Classifier_linear_cnn_extra_pool_less, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35, 40, 50]\n",
    "        conv_stride = [1, 1, 1, 1, 1]\n",
    "        conv_kernel_size = [2, 2, 2, 2, 2]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [4, 1, 4, 1, 4]\n",
    "        pool_stride = [4, 1, 4, 1, 4]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "\n",
    "        self.conv4 = nn.Conv1d(conv_size[2], conv_size[3], conv_kernel_size[3], conv_stride[3])\n",
    "        self.bn4 = nn.BatchNorm1d(conv_size[3])\n",
    "        self.pool4 = nn.MaxPool1d(pool_kernel[3], pool_stride[3])\n",
    "\n",
    "        self.conv5 = nn.Conv1d(conv_size[3], conv_size[4], conv_kernel_size[4], conv_stride[4])\n",
    "        self.bn5 = nn.BatchNorm1d(conv_size[4])\n",
    "        self.pool5 = nn.MaxPool1d(pool_kernel[4], pool_stride[4])\n",
    "        \n",
    "        \n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv4 = self.pool4(F.relu(self.bn4(self.conv4(outconv3))))\n",
    "        # print(outconv4.shape)\n",
    "        outconv5 = self.pool5(F.relu(self.bn5(self.conv5(outconv4))))\n",
    "        # print(outconv5.shape)\n",
    "        outconv5 = outconv5.view(batch_size, -1)\n",
    "        # print(outconv5.shape)\n",
    "        outfc1 = (F.relu(self.fc1(outconv5)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class CNN_EEG_Classifier_3cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"MORE CNNs, MORE LAYERS, MORE POWER\n",
    "        That was a lie\"\"\"\n",
    "        super(CNN_EEG_Classifier_3cnn, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35]\n",
    "        conv_stride = [1, 1, 1]\n",
    "        conv_kernel_size = [2, 2, 2]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1]\n",
    "        pool_stride = [1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 7500)\n",
    "        self.fc2 = nn.Linear(7500, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv3 = outconv3.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv3)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class CNN_EEG_Classifier_3cnn_high_kernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"MORE CNNs, MORE LAYERS, MORE POWER\n",
    "        That was a lie\"\"\"\n",
    "        super(CNN_EEG_Classifier_3cnn_high_kernel, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35]\n",
    "        conv_stride = [1, 1, 1]\n",
    "        conv_kernel_size = [4, 4, 4]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1]\n",
    "        pool_stride = [1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 7500)\n",
    "        self.fc2 = nn.Linear(7500, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv3 = outconv3.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv3)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_EEG_Classifier_10cnn_mix_kernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"MORE CNNs, MORE LAYERS, MORE POWER\n",
    "        That was a lie\n",
    "        Still, trying 10 CNNs because I am dumb\"\"\"\n",
    "        super(CNN_EEG_Classifier_10cnn_mix_kernel, self).__init__()\n",
    "\n",
    "        conv_size = [25, 30, 35, 40, 45, 50, 55, 60, 65, 70]\n",
    "        conv_stride = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "        conv_kernel_size = [2, 3, 2, 3, 2, 3, 2, 3, 2, 3]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1, 1, 1, 1, 1, 1, 4, 1]\n",
    "        pool_stride = [1, 4, 1, 1, 1, 1, 1, 1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(conv_size[2], conv_size[3], conv_kernel_size[3], conv_stride[3])\n",
    "        self.bn4 = nn.BatchNorm1d(conv_size[3])\n",
    "        self.pool4 = nn.MaxPool1d(pool_kernel[3], pool_stride[3])\n",
    "        \n",
    "        self.conv5 = nn.Conv1d(conv_size[3], conv_size[4], conv_kernel_size[4], conv_stride[4])\n",
    "        self.bn5 = nn.BatchNorm1d(conv_size[4])\n",
    "        self.pool5 = nn.MaxPool1d(pool_kernel[4], pool_stride[4])\n",
    "        \n",
    "        self.conv6 = nn.Conv1d(conv_size[4], conv_size[5], conv_kernel_size[5], conv_stride[5])\n",
    "        self.bn6 = nn.BatchNorm1d(conv_size[5])\n",
    "        self.pool6 = nn.MaxPool1d(pool_kernel[5], pool_stride[5])\n",
    "        \n",
    "        self.conv7 = nn.Conv1d(conv_size[5], conv_size[6], conv_kernel_size[6], conv_stride[6])\n",
    "        self.bn7 = nn.BatchNorm1d(conv_size[6])\n",
    "        self.pool7 = nn.MaxPool1d(pool_kernel[6], pool_stride[6])\n",
    "        \n",
    "        self.conv8 = nn.Conv1d(conv_size[6], conv_size[7], conv_kernel_size[7], conv_stride[7])\n",
    "        self.bn8 = nn.BatchNorm1d(conv_size[7])\n",
    "        self.pool8 = nn.MaxPool1d(pool_kernel[7], pool_stride[7])\n",
    "        \n",
    "        self.conv9 = nn.Conv1d(conv_size[7], conv_size[8], conv_kernel_size[8], conv_stride[8])\n",
    "        self.bn9 = nn.BatchNorm1d(conv_size[8])\n",
    "        self.pool9 = nn.MaxPool1d(pool_kernel[8], pool_stride[8])\n",
    "        \n",
    "        self.conv10 = nn.Conv1d(conv_size[8], conv_size[9], conv_kernel_size[9], conv_stride[9])\n",
    "        self.bn10 = nn.BatchNorm1d(conv_size[9])\n",
    "        self.pool10 = nn.MaxPool1d(pool_kernel[9], pool_stride[9])\n",
    "        \n",
    "\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv4 = self.pool4(F.relu(self.bn4(self.conv4(outconv3))))\n",
    "        # print(outconv4.shape)\n",
    "        outconv5 = self.pool5(F.relu(self.bn5(self.conv5(outconv4))))\n",
    "        outconv6 = self.pool6(F.relu(self.bn6(self.conv6(outconv5))))\n",
    "        outconv7 = self.pool7(F.relu(self.bn7(self.conv7(outconv6))))\n",
    "        outconv8 = self.pool8(F.relu(self.bn8(self.conv8(outconv7))))\n",
    "        outconv9 = self.pool9(F.relu(self.bn9(self.conv9(outconv8))))\n",
    "        outconv10 = self.pool10(F.relu(self.bn10(self.conv10(outconv9))))\n",
    "        \n",
    "        outconv10 = outconv10.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv10)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_EEG_Classifier_3cnn_medium_kernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Trying kernel size 3 with 3 CNN model\"\"\"\n",
    "        super(CNN_EEG_Classifier_3cnn_medium_kernel, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35]\n",
    "        conv_stride = [1, 1, 1]\n",
    "        conv_kernel_size = [3, 3, 3]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1]\n",
    "        pool_stride = [1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 7500)\n",
    "        self.fc2 = nn.Linear(7500, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv3 = outconv3.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv3)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_EEG_Classifier_3cnn_medium_kernel_leaky(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Trying kernel size 3 with 3 CNN model with leakyReLU\"\"\"\n",
    "        super(CNN_EEG_Classifier_3cnn_medium_kernel_leaky, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35]\n",
    "        conv_stride = [1, 1, 1]\n",
    "        conv_kernel_size = [3, 3, 3]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1]\n",
    "        pool_stride = [1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 7500)\n",
    "        self.fc2 = nn.Linear(7500, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.leaky_relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.leaky_relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.leaky_relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv3 = outconv3.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.leaky_relu(self.fc1(outconv3)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.leaky_relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_EEG_Classifier_3cnn_medium_kernel_stride(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Trying stride 3 with 3 CNN model, 3 CNN kernel size\"\"\"\n",
    "        super(CNN_EEG_Classifier_3cnn_medium_kernel_stride, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35]\n",
    "        conv_stride = [3, 3, 3]\n",
    "        conv_kernel_size = [3, 3, 3]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1]\n",
    "        pool_stride = [1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv3 = outconv3.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv3)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNN_EEG_Classifier_best1_5cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"BEST MODEL ATTEMPT 1: 20 epochs 64 batch size, 3 linear layers, learning rate 0.1, maxpool TBD (thinking 2), 5 CNN, kernel stride 2, kernel size 4, 1 dropout 50%\"\"\"\n",
    "        super(CNN_EEG_Classifier_best1_5cnn, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35, 40, 45]\n",
    "        conv_stride = [2, 2, 2, 2, 2]\n",
    "        conv_kernel_size = [4, 4, 4, 4, 4]\n",
    "        n_layers = len(conv_size)\n",
    "\n",
    "        pool_kernel = [4, 1, 1, 1, 4]\n",
    "        pool_stride = [4, 1, 1, 1, 4]\n",
    "                \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "\n",
    "        self.conv4 = nn.Conv1d(conv_size[2], conv_size[3], conv_kernel_size[3], conv_stride[3])\n",
    "        self.bn4 = nn.BatchNorm1d(conv_size[3])\n",
    "        self.pool4 = nn.MaxPool1d(pool_kernel[3], pool_stride[3])\n",
    "\n",
    "        self.conv5 = nn.Conv1d(conv_size[3], conv_size[4], conv_kernel_size[4], conv_stride[4])\n",
    "        self.bn5 = nn.BatchNorm1d(conv_size[4])\n",
    "        self.pool5 = nn.MaxPool1d(pool_kernel[4], pool_stride[4])\n",
    "        \n",
    "        \n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 500)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(500, 150)\n",
    "        self.fc3 = nn.Linear(150, 3)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv4 = self.pool4(F.relu(self.bn4(self.conv4(outconv3))))\n",
    "        # print(outconv4.shape)\n",
    "        outconv5 = self.pool5(F.relu(self.bn5(self.conv5(outconv4))))\n",
    "        # print(outconv5.shape)\n",
    "        outconv5 = outconv5.view(batch_size, -1)\n",
    "        # print(outconv5.shape)\n",
    "        outfc1 = self.dropout1(F.relu(self.fc1(outconv5)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = F.relu(self.fc3(outfc2))\n",
    "        \n",
    "        out = F.softmax(outfc3, dim = 1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def get_accuracy(model, train=True, train_data = trainloader, val_data = valloader):\n",
    "    if train:\n",
    "        dataloader = train_data\n",
    "    else:\n",
    "        dataloader = val_data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dataloader:\n",
    "            outputs = model(imgs.float())\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            _, labels = torch.max(labels, dim=1)\n",
    "            # print(predicted, labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return 100 * correct / total\n",
    "torch.manual_seed(5)\n",
    "def train_old(model, batch_size=1, traindata = trainloader, valdata = valloader, num_epochs=10, rate = 0.001, name = \"CNN\"):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=rate, momentum=0.9)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(traindata):\n",
    "\n",
    "            # print(imgs.shape)\n",
    "            imgs = imgs.to(torch.float32)\n",
    "            out = model(imgs)             # forward pass\n",
    "            # print(out.shape)\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, train=True, train_data=traindata)) # compute training accuracy\n",
    "            val_acc.append(get_accuracy(model, train=False, val_data = valdata))  # compute validation accuracy\n",
    "            n += 1\n",
    "            print(\"Iteration:\", n)\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"Training Accuracy:\", get_accuracy(model, train=True, train_data=traindata))\n",
    "        print(\"Validation Accuracy:\", get_accuracy(model, train=False, val_data = valdata))\n",
    "            \n",
    "    print(\"Iterations:\", n)\n",
    "    # plotting\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.savefig(\"Accuracy Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "\n",
    "def train_adam_ce(model, batch_size=1, traindata = trainloader, valdata = valloader, num_epochs=10, rate = 0.001, name = \"CNN\"):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=rate)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(traindata):\n",
    "\n",
    "            # print(imgs.shape)\n",
    "            imgs = imgs.to(torch.float32)\n",
    "            out = model(imgs)             # forward pass\n",
    "            # print(out.shape)\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, train=True, train_data=traindata)) # compute training accuracy\n",
    "            val_acc.append(get_accuracy(model, train=False, val_data = valdata))  # compute validation accuracy\n",
    "            n += 1\n",
    "            print(\"Iteration:\", n)\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"Training Accuracy:\", get_accuracy(model, train=True, train_data=traindata))\n",
    "        print(\"Validation Accuracy:\", get_accuracy(model, train=False, val_data = valdata))\n",
    "            \n",
    "    print(\"Iterations:\", n)\n",
    "    # plotting\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.savefig(\"Accuracy Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "\n",
    "def train_adam_ce_step_lr(model, batch_size=1, traindata = trainloader, valdata = valloader, num_epochs=10, rate = 0.001, name = \"CNN\"):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=rate)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(traindata):\n",
    "\n",
    "            if epoch < num_epochs//3:\n",
    "                rate = rate\n",
    "            elif epoch < 2*num_epochs//3:\n",
    "                rate = rate/10\n",
    "            else:\n",
    "                rate = rate/100  \n",
    "            print(rate)         \n",
    "\n",
    "            # print(imgs.shape)\n",
    "            imgs = imgs.to(torch.float32)\n",
    "            out = model(imgs)             # forward pass\n",
    "            # print(out.shape)\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, train=True, train_data=traindata)) # compute training accuracy\n",
    "            val_acc.append(get_accuracy(model, train=False, val_data = valdata))  # compute validation accuracy\n",
    "            n += 1\n",
    "            print(\"Iteration:\", n)\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"Training Accuracy:\", get_accuracy(model, train=True, train_data=traindata))\n",
    "        print(\"Validation Accuracy:\", get_accuracy(model, train=False, val_data = valdata))\n",
    "            \n",
    "    print(\"Iterations:\", n)\n",
    "    # plotting\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.savefig(\"Accuracy Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "\n",
    "def train_adam_ce_lin_lr(model, batch_size=1, traindata = trainloader, valdata = valloader, num_epochs=10, rate = 0.001, name = \"CNN\"):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=rate)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(traindata):\n",
    "\n",
    "            lr_rate = rate/num_epochs\n",
    "            rate = lr_rate*(num_epochs - epoch)\n",
    "            print(rate)\n",
    "\n",
    "            # print(imgs.shape)\n",
    "            imgs = imgs.to(torch.float32)\n",
    "            out = model(imgs)             # forward pass\n",
    "            # print(out.shape)\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, train=True, train_data=traindata)) # compute training accuracy\n",
    "            val_acc.append(get_accuracy(model, train=False, val_data = valdata))  # compute validation accuracy\n",
    "            n += 1\n",
    "            print(\"Iteration:\", n)\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"Training Accuracy:\", get_accuracy(model, train=True, train_data=traindata))\n",
    "        print(\"Validation Accuracy:\", get_accuracy(model, train=False, val_data = valdata))\n",
    "            \n",
    "    print(\"Iterations:\", n)\n",
    "    # plotting\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.savefig(\"Accuracy Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "\n",
    "eegclassifier1 = CNN_EEG_Classifier_3cnn_medium_kernel()\n",
    "eegclassifier2 = CNN_EEG_Classifier_3cnn_medium_kernel_leaky()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Iteration: 2\n",
      "Iteration: 3\n",
      "Iteration: 4\n",
      "Iteration: 5\n",
      "Iteration: 6\n",
      "Iteration: 7\n",
      "Iteration: 8\n",
      "Iteration: 9\n",
      "Iteration: 10\n",
      "Iteration: 11\n",
      "Iteration: 12\n",
      "Iteration: 13\n",
      "Iteration: 14\n",
      "Iteration: 15\n",
      "Iteration: 16\n",
      "Epoch: 0\n",
      "Training Accuracy: 38.0589430894309\n",
      "Validation Accuracy: 39.6286231884058\n",
      "Iteration: 17\n",
      "Iteration: 18\n",
      "Iteration: 19\n",
      "Iteration: 20\n",
      "Iteration: 21\n",
      "Iteration: 22\n",
      "Iteration: 23\n",
      "Iteration: 24\n",
      "Iteration: 25\n",
      "Iteration: 26\n",
      "Iteration: 27\n",
      "Iteration: 28\n",
      "Iteration: 29\n",
      "Iteration: 30\n",
      "Iteration: 31\n",
      "Iteration: 32\n",
      "Epoch: 1\n",
      "Training Accuracy: 39.329268292682926\n",
      "Validation Accuracy: 40.57971014492754\n",
      "Iteration: 33\n",
      "Iteration: 34\n",
      "Iteration: 35\n",
      "Iteration: 36\n",
      "Iteration: 37\n",
      "Iteration: 38\n",
      "Iteration: 39\n",
      "Iteration: 40\n",
      "Iteration: 41\n",
      "Iteration: 42\n",
      "Iteration: 43\n",
      "Iteration: 44\n",
      "Iteration: 45\n",
      "Iteration: 46\n",
      "Iteration: 47\n",
      "Iteration: 48\n",
      "Epoch: 2\n",
      "Training Accuracy: 40.90447154471545\n",
      "Validation Accuracy: 38.903985507246375\n",
      "Iteration: 49\n",
      "Iteration: 50\n",
      "Iteration: 51\n",
      "Iteration: 52\n",
      "Iteration: 53\n",
      "Iteration: 54\n",
      "Iteration: 55\n",
      "Iteration: 56\n",
      "Iteration: 57\n",
      "Iteration: 58\n",
      "Iteration: 59\n",
      "Iteration: 60\n",
      "Iteration: 61\n",
      "Iteration: 62\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain_adam_ce\u001b[49m\u001b[43m(\u001b[49m\u001b[43meegclassifier1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m127\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCNN_EEG_Classifier_3cnn_medium_kernel train_adam_ce\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m,get_accuracy(eegclassifier1, train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, train_data \u001b[38;5;241m=\u001b[39m testloader))\n",
      "Cell \u001b[1;32mIn[5], line 94\u001b[0m, in \u001b[0;36mtrain_adam_ce\u001b[1;34m(model, batch_size, traindata, valdata, num_epochs, rate, name)\u001b[0m\n\u001b[0;32m     91\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, labels) \u001b[38;5;66;03m# compute the total loss\u001b[39;00m\n\u001b[0;32m     92\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()               \u001b[38;5;66;03m# backward pass (compute parameter updates)\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m              \u001b[38;5;66;03m# make the updates for each parameter\u001b[39;00m\n\u001b[0;32m     95\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()         \u001b[38;5;66;03m# a clean up step for PyTorch\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# save the current training information\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\togar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\togar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\togar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    158\u001b[0m         group,\n\u001b[0;32m    159\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    164\u001b[0m         state_steps)\n\u001b[1;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\togar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\togar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\optim\\adam.py:392\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    391\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 392\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    395\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_adam_ce(eegclassifier1, batch_size = 127, num_epochs = 5, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel train_adam_ce\")\n",
    "print(\"Test accuracy:\",get_accuracy(eegclassifier1, train = True, train_data = testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adam_ce_step_lr(eegclassifier1, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel train_adam_ce_step_lr\")\n",
    "print(\"Test accuracy:\",get_accuracy(eegclassifier1, train = True, train_data = testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adam_ce_lin_lr(eegclassifier1, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel train_adam_ce_lin_lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adam_ce_step_lr(eegclassifier2, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel_leaky train_adam_ce_step_lr\")\n",
    "print(\"Test accuracy:\",get_accuracy(eegclassifier2, train = True, train_data = testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adam_ce(eegclassifier2, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel_leaky train_adam_ce\")\n",
    "print(\"Test accuracy:\",get_accuracy(eegclassifier2, train = True, train_data = testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adam_ce_lin_lr(eegclassifier2, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel_leaky train_adam_ce_lin_lr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
