{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_13284\\2670626108.py:68: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import *\n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=6):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=6):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "def calcsnr(prefilter, filtered):\n",
    "    filteredsum = 0\n",
    "    denomsum = 0\n",
    "    for i in range(len(prefilter)):\n",
    "        filteredsum = filteredsum+filtered[i]*filtered[i]\n",
    "        denomsum = denomsum+ (filtered[i]-prefilter[i])*(filtered[i]-prefilter[i])\n",
    "    return 10*math.log10(filteredsum/denomsum)\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, eeglist, labels, transform=None, target_transform=None):\n",
    "        self.labels = torch.from_numpy(np.array(labels))\n",
    "        self.labels = self.labels.to(torch.float32)\n",
    "        self.eeglist = eeglist\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        raw = self.eeglist[idx]\n",
    "        eeg = torch.from_numpy(raw.get_data())\n",
    "        eeg = eeg.to(torch.float32)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return eeg, label\n",
    "\n",
    "data_list = {\"raw\":[], \"preprocessed\":[], \"manual_preprocess\":[], \"rawsample\": [], \"preprocessedsample\":[], \"manual_preprocesssample\":[]}\n",
    "labels = []\n",
    "readtsv = pd.read_csv('participants.tsv', sep = '\\t')\n",
    "\n",
    "channel_names = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']\n",
    "for i in range(1,89):\n",
    "\n",
    "    filteredpath = r\"D:\\Laptop Archive\\Sunny\\School Work\\UofT 2023-2024\\APS360\\derivatives\\sub-%s\\eeg\"%(str(i).zfill(3))\n",
    "    filteredfile = glob.glob(os.path.join(filteredpath, '*.set'))\n",
    "    filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
    "\n",
    "\n",
    "    rawpath = r\"D:\\Laptop Archive\\Sunny\\School Work\\UofT 2023-2024\\APS360\\Raw Data\\sub-%s\\eeg\"%(str(i).zfill(3))\n",
    "    file = glob.glob(os.path.join(rawpath, '*.set'))\n",
    "    raw = mne.io.read_raw_eeglab(file[0], preload = True)\n",
    "\n",
    "    data_list['raw'].append(raw)\n",
    "    data_list['preprocessed'].append(filtered)\n",
    "    \n",
    "\n",
    "    label = readtsv['Group'][i-1]\n",
    "    if label == 'A':\n",
    "        labels.append([0,0,1])\n",
    "    elif label == 'F':\n",
    "        labels.append([0,1,0])\n",
    "    elif label == 'C':\n",
    "        labels.append([1,0,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import *\n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import ICA\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import clear_output \n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=6):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=6):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "def calcsnr(prefilter, filtered):\n",
    "    filteredsum = 0\n",
    "    denomsum = 0\n",
    "    for i in range(len(prefilter)):\n",
    "        filteredsum = filteredsum+filtered[i]*filtered[i]\n",
    "        denomsum = denomsum+ (filtered[i]-prefilter[i])*(filtered[i]-prefilter[i])\n",
    "    return 10*math.log10(filteredsum/denomsum)\n",
    "\n",
    "\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, eeglist, labels, transform=None, target_transform=None):\n",
    "        self.labels = torch.from_numpy(np.array(labels))\n",
    "        self.labels = self.labels.to(torch.float32)\n",
    "        self.eeglist = eeglist\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        raw = self.eeglist[idx]\n",
    "        eeg = torch.from_numpy(raw.get_data())\n",
    "        eeg = eeg.to(torch.float32)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return eeg, label\n",
    "\n",
    "bandwidth_split_data = {'alpha': [], 'beta': [], 'delta': [], 'gamma': [],'alpha_processed': [], 'beta_processed': [], 'delta_processed': [], 'gamma_processed': []}\n",
    "labels = []\n",
    "readtsv = pd.read_csv('participants.tsv', sep = '\\t')\n",
    "\n",
    "def splitbandwidth(band, data):\n",
    "    return data.filter(l_freq = band[0], h_freq=band[1])\n",
    "\n",
    "channel_names = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']\n",
    "for i in range(1,89):\n",
    "\n",
    "    rawpath = r\"D:\\Laptop Archive\\Sunny\\School Work\\UofT 2023-2024\\APS360\\Raw Data\\sub-%s\\eeg\"%(str(i).zfill(3))\n",
    "    file = glob.glob(os.path.join(rawpath, '*.set'))\n",
    "    raw = mne.io.read_raw_eeglab(file[0], preload = True)\n",
    "\n",
    "    bandwidth_split_data['delta'].append(splitbandwidth([0.5, 4], raw.copy()))\n",
    "    bandwidth_split_data['alpha'].append(splitbandwidth([8, 12], raw.copy()))\n",
    "    bandwidth_split_data['beta'].append(splitbandwidth([13, 30], raw.copy()))\n",
    "    bandwidth_split_data['gamma'].append(splitbandwidth([30, 80], raw.copy()))\n",
    "    clear_output()\n",
    "\n",
    "    label = readtsv['Group'][i-1]\n",
    "    if label == 'A':\n",
    "        labels.append([0,0,1])\n",
    "    elif label == 'F':\n",
    "        labels.append([0,1,0])\n",
    "    elif label == 'C':\n",
    "        labels.append([1,0,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne_icalabel import label_components\n",
    "exclusion = ['line noise', 'heartbeat', 'eye blink']\n",
    "\n",
    "def manual_process(raw, plotting = True):\n",
    "    freq_low = 0.5\n",
    "    freq_high = 45\n",
    "    iirparams = dict(order = 4, ftype = 'butter')\n",
    "\n",
    "    raw.filter(freq_low, freq_high, method = 'iir', iir_params = iirparams)\n",
    "\n",
    "    # Create ICA object and fit it to the data\n",
    "    ica = ICA(n_components=19, random_state=97, verbose = False)\n",
    "    ica.fit(raw)\n",
    "\n",
    "    # Plot ICA components to identify artifacts\n",
    "    icalabels = label_components(raw, ica, method = 'iclabel')\n",
    "    if plotting == True:\n",
    "        ica.plot_components()\n",
    "        picks = list(range(0,18))\n",
    "        ica.plot_properties(raw, picks=picks)\n",
    "        print(icalabels)\n",
    "    ica.exclude = []\n",
    "    for i, label in enumerate(icalabels):\n",
    "        if label in exclusion:\n",
    "            ica.exclude.append(i)\n",
    "    ica.apply(raw)\n",
    "            \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "for subject in data_list['raw']:\n",
    "    raw = subject.copy().load_data()\n",
    "    data_list['manual_preprocess'].append(manual_process(raw, plotting = False))\n",
    "    clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Fitting ICA to data using 19 channels (please be patient, this may take a while)\n",
      "Selecting by number: 19 components\n",
      "Fitting ICA took 9.8s.\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_32312\\2725101412.py:16: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  icalabels = label_components(raw, ica, method = 'iclabel')\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_32312\\2725101412.py:16: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
      "  icalabels = label_components(raw, ica, method = 'iclabel')\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_32312\\2725101412.py:16: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  icalabels = label_components(raw, ica, method = 'iclabel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (19 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 19 PCA components\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Fitting ICA to data using 19 channels (please be patient, this may take a while)\n",
      "Selecting by number: 19 components\n",
      "Fitting ICA took 6.9s.\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_32312\\2725101412.py:16: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  icalabels = label_components(raw, ica, method = 'iclabel')\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_32312\\2725101412.py:16: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
      "  icalabels = label_components(raw, ica, method = 'iclabel')\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_32312\\2725101412.py:16: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  icalabels = label_components(raw, ica, method = 'iclabel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (19 components)\n",
      "    Zeroing out 0 ICA components\n",
      "    Projecting back using 19 PCA components\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 45 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 45.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Fitting ICA to data using 19 channels (please be patient, this may take a while)\n",
      "Selecting by number: 19 components\n",
      "Fitting ICA took 18.0s.\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_32312\\2725101412.py:16: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
      "  icalabels = label_components(raw, ica, method = 'iclabel')\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_32312\\2725101412.py:16: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
      "  icalabels = label_components(raw, ica, method = 'iclabel')\n",
      "C:\\Users\\sunny\\AppData\\Local\\Temp\\ipykernel_32312\\2725101412.py:16: RuntimeWarning: The provided ICA instance was fitted with a 'fastica' algorithm. ICLabel was designed with extended infomax ICA decompositions. To use the extended infomax algorithm, use the 'mne.preprocessing.ICA' instance with the arguments 'ICA(method='infomax', fit_params=dict(extended=True))' (scikit-learn) or 'ICA(method='picard', fit_params=dict(ortho=False, extended=True))' (python-picard).\n",
      "  icalabels = label_components(raw, ica, method = 'iclabel')\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output \n",
    "for n in range (len(bandwidth_split_data['alpha'])):\n",
    "    alpha = bandwidth_split_data['alpha'][n].copy().load_data()\n",
    "    beta = bandwidth_split_data['beta'][n].copy().load_data()\n",
    "    gamma = bandwidth_split_data['gamma'][n].copy().load_data()\n",
    "    delta = bandwidth_split_data['delta'][n].copy().load_data()\n",
    "    bandwidth_split_data['alpha_processed'].append(manual_process(alpha, plotting = False))\n",
    "    bandwidth_split_data['beta_processed'].append(manual_process(beta, plotting = False))\n",
    "    bandwidth_split_data['gamma_processed'].append(manual_process(gamma, plotting = False))\n",
    "    bandwidth_split_data['delta_processed'].append(manual_process(delta, plotting = False))\n",
    "    clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m totals[x]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m-\u001b[39mcount\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m20\u001b[39m:\n\u001b[0;32m     19\u001b[0m   n \u001b[38;5;241m=\u001b[39m data_list[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanual_preprocess\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 20\u001b[0m   vallist\u001b[38;5;241m.\u001b[39mappend(\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m   vallabels\u001b[38;5;241m.\u001b[39mappend(labels[i])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m<decorator-gen-238>:12\u001b[0m, in \u001b[0;36mcrop\u001b[1;34m(self, tmin, tmax, include_tmax, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mne\\io\\base.py:1527\u001b[0m, in \u001b[0;36mBaseRaw.crop\u001b[1;34m(self, tmin, tmax, include_tmax, verbose)\u001b[0m\n\u001b[0;32m   1521\u001b[0m     \u001b[38;5;66;03m# When self.info['meas_date'] is None (which is guaranteed if\u001b[39;00m\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;66;03m# self.annotations.orig_time is None), when we do the\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m     \u001b[38;5;66;03m# self.set_annotations, it's assumed that the annotations onset\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m     \u001b[38;5;66;03m# are relative to first_time, so we have to subtract it, then\u001b[39;00m\n\u001b[0;32m   1525\u001b[0m     \u001b[38;5;66;03m# set_annotations will put it back.\u001b[39;00m\n\u001b[0;32m   1526\u001b[0m     annotations\u001b[38;5;241m.\u001b[39monset \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_time\n\u001b[1;32m-> 1527\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m<decorator-gen-233>:12\u001b[0m, in \u001b[0;36mset_annotations\u001b[1;34m(self, annotations, emit_warning, on_missing, verbose)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sunny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mne\\io\\base.py:738\u001b[0m, in \u001b[0;36mBaseRaw.set_annotations\u001b[1;34m(self, annotations, emit_warning, on_missing, verbose)\u001b[0m\n\u001b[0;32m    735\u001b[0m new_annotations\u001b[38;5;241m.\u001b[39m_prune_ch_names(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo, on_missing)\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m annotations\u001b[38;5;241m.\u001b[39morig_time \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    737\u001b[0m     new_annotations\u001b[38;5;241m.\u001b[39mcrop(\n\u001b[1;32m--> 738\u001b[0m         \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimes\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m delta, emit_warning\u001b[38;5;241m=\u001b[39memit_warning\n\u001b[0;32m    739\u001b[0m     )\n\u001b[0;32m    740\u001b[0m     new_annotations\u001b[38;5;241m.\u001b[39monset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_time\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\sunny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mne\\io\\base.py:1855\u001b[0m, in \u001b[0;36mBaseRaw.times\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1854\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Time points.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1855\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43m_arange_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msfreq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1856\u001b[0m     out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\sunny\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\mne\\utils\\numerics.py:1112\u001b[0m, in \u001b[0;36m_arange_div_fallback\u001b[1;34m(n, d)\u001b[0m\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arange_div_fallback\u001b[39m(n, d):\n\u001b[1;32m-> 1112\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1113\u001b[0m     x \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m d\n\u001b[0;32m   1114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "totals = [485.5, 276.5, 402]\n",
    "trainlist, vallist, testlist, trainlabels, vallabels, testlabels = [],[],[],[],[],[]\n",
    "labelonehot = [[0,0,1], [0,1,0], [1,0,0]]\n",
    "#make sure enough of each group in each partition of data\n",
    "for x, label in enumerate(labelonehot):\n",
    "  count = 0\n",
    "  for i in range (len(labels)):\n",
    "    if labels[i] == label:\n",
    "      m = 0\n",
    "      # print(len(n.get_data()[0]))\n",
    "      while 15000*(m+1) < len(data_list['manual_preprocess'][i].copy().get_data()[0]):\n",
    "        if totals[x]*2-count>100:\n",
    "          n = data_list['manual_preprocess'][i].copy()\n",
    "          trainlist.append(n.crop(m*30,(m+1)*30))\n",
    "          trainlabels.append(labels[i])\n",
    "        if totals[x]*2-count>20:\n",
    "          n = data_list['manual_preprocess'][i].copy()\n",
    "          vallist.append(n.crop(m*30,(m+1)*30))\n",
    "          vallabels.append(labels[i])\n",
    "        else:\n",
    "          n = data_list['manual_preprocess'][i].copy()\n",
    "          testlist.append(n.crop(m*30, (m+1)*30))\n",
    "          testlabels.append(labels[i])\n",
    "        count = count + 1\n",
    "        m = m+1\n",
    "\n",
    "\n",
    "trainset = EEGDataset(trainlist, trainlabels)\n",
    "valset = EEGDataset(vallist, vallabels)\n",
    "testset = EEGDataset(testlist, testlabels)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "valloader = DataLoader(valset, batch_size = 64, shuffle = True)\n",
    "testloader = DataLoader(testset, batch_size = 64, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "totals = [485.5, 276.5, 402]\n",
    "alphatrainlist, alphavallist, alphatestlist, alphatrainlabels, alphavallabels, alphatestlabels = [],[],[],[],[],[]\n",
    "betatrainlist, betavallist, betatestlist, betatrainlabels, betavallabels, betatestlabels = [],[],[],[],[],[]\n",
    "gammatrainlist, gammavallist, gammatestlist, gammatrainlabels, gammavallabels, gammatestlabels = [],[],[],[],[],[]\n",
    "deltatrainlist, deltavallist, deltatestlist, deltatrainlabels, deltavallabels, deltatestlabels = [],[],[],[],[],[]\n",
    "trainlist, vallist, testlist, trainlabels, vallabels, testlabels = [],[],[],[],[],[]\n",
    "\n",
    "labelonehot = [[0,0,1], [0,1,0], [1,0,0]]\n",
    "#make sure enough of each group in each partition of data\n",
    "for x, label in enumerate(labelonehot):\n",
    "  count = 0\n",
    "  for i in range (len(labels)):\n",
    "    if labels[i] == label:\n",
    "      m = 0\n",
    "      # print(len(n.get_data()[0]))\n",
    "      while 15000*(m+1) < len(bandwidth_split_data['alpha'][i].copy().get_data()[0]):\n",
    "        if totals[x]*2-count>100:\n",
    "          A = bandwidth_split_data['alpha'][i].copy()\n",
    "          B = bandwidth_split_data['beta'][i].copy()\n",
    "          G = bandwidth_split_data['gamma'][i].copy()\n",
    "          D = bandwidth_split_data['delta'][i].copy()\n",
    "          alphatrainlist.append(A.crop(m*30,(m+1)*30))\n",
    "          alphatrainlabels.append(labels[i])\n",
    "          \n",
    "          betatrainlist.append(B.crop(m*30,(m+1)*30))\n",
    "          betatrainlabels.append(labels[i])\n",
    "          gammatrainlist.append(G.crop(m*30,(m+1)*30))\n",
    "          gammatrainlabels.append(labels[i])\n",
    "          deltatrainlist.append(D.crop(m*30,(m+1)*30))\n",
    "          deltatrainlabels.append(labels[i])\n",
    "          trainlist.append(A)\n",
    "          trainlist.append(B)\n",
    "          trainlist.append(G)\n",
    "          trainlist.append(D)\n",
    "          for j in range(0,4):  \n",
    "            trainlabels.append(labels[i])\n",
    "        if totals[x]*2-count>20:\n",
    "          A = bandwidth_split_data['alpha'][i].copy()\n",
    "          B = bandwidth_split_data['beta'][i].copy()\n",
    "          G = bandwidth_split_data['gamma'][i].copy()\n",
    "          D = bandwidth_split_data['delta'][i].copy()\n",
    "          alphavallist.append(A.crop(m*30,(m+1)*30))\n",
    "          alphavallabels.append(labels[i])\n",
    "          betavallist.append(B.crop(m*30,(m+1)*30))\n",
    "          betavallabels.append(labels[i])\n",
    "          gammavallist.append(G.crop(m*30,(m+1)*30))\n",
    "          gammavallabels.append(labels[i])\n",
    "          deltavallist.append(D.crop(m*30,(m+1)*30))\n",
    "          deltavallabels.append(labels[i])\n",
    "          vallist.append(A)\n",
    "          vallist.append(B)\n",
    "          vallist.append(G)\n",
    "          vallist.append(D)\n",
    "          for j in range(0,4):  \n",
    "            vallabels.append(labels[i])\n",
    "        else:\n",
    "          A = bandwidth_split_data['alpha'][i].copy()\n",
    "          B = bandwidth_split_data['beta'][i].copy()\n",
    "          G = bandwidth_split_data['gamma'][i].copy()\n",
    "          D = bandwidth_split_data['delta'][i].copy()\n",
    "          alphatestlist.append(A.crop(m*30,(m+1)*30))\n",
    "          alphatestlabels.append(labels[i])\n",
    "          betatestlist.append(B.crop(m*30,(m+1)*30))\n",
    "          betatestlabels.append(labels[i])\n",
    "          gammatestlist.append(G.crop(m*30,(m+1)*30))\n",
    "          gammatestlabels.append(labels[i])\n",
    "          deltatestlist.append(D.crop(m*30,(m+1)*30))\n",
    "          deltatestlabels.append(labels[i])\n",
    "          testlist.append(A)\n",
    "          testlist.append(B)\n",
    "          testlist.append(G)\n",
    "          testlist.append(D)\n",
    "          for j in range(0,4):  \n",
    "            testlabels.append(labels[i])\n",
    "        count = count + 1\n",
    "        m = m+1\n",
    "        gc.collect()\n",
    "\n",
    "alphatrainset = EEGDataset(alphatrainlist, alphatrainlabels)\n",
    "betatrainset = EEGDataset(betatrainlist, betatrainlabels)\n",
    "gammatrainset = EEGDataset(gammatrainlist, gammatrainlabels)\n",
    "deltatrainset = EEGDataset(deltatrainlist, deltatrainlabels)\n",
    "fulltrainset = EEGDataset(trainlist, trainlabels)\n",
    "\n",
    "alphavalset = EEGDataset(alphavallist, alphavallabels)\n",
    "betaavalset = EEGDataset(betavallist, betavallabels)\n",
    "gammavalset = EEGDataset(gammavallist, gammavallabels)\n",
    "deltavalset = EEGDataset(deltavallist, deltavallabels)\n",
    "fullvalset = EEGDataset(vallist, vallabels)\n",
    "\n",
    "alphatestset = EEGDataset(alphatestlist, alphatestlabels)\n",
    "betaatestset = EEGDataset(betatestlist, betatestlabels)\n",
    "gammatestset = EEGDataset(gammatestlist, gammatestlabels)\n",
    "deltatestset = EEGDataset(deltatestlist, deltatestlabels)\n",
    "fulltestset = EEGDataset(testlist, testlabels)\n",
    "\n",
    "alphatrainloader = DataLoader(alphatrainset, batch_size = 64, shuffle = True)\n",
    "betatrainloader = DataLoader(betatrainset, batch_size = 64, shuffle = True)\n",
    "gammatrainloader = DataLoader(gammatrainset, batch_size = 64, shuffle = True)\n",
    "deltatrainloader = DataLoader(deltatrainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "alphavalloader = DataLoader(alphavalset, batch_size = 64, shuffle = True)\n",
    "betavalloader = DataLoader(betavalset, batch_size = 64, shuffle = True)\n",
    "gammavalloader = DataLoader(gammavalset, batch_size = 64, shuffle = True)\n",
    "deltavalloader = DataLoader(deltavalset, batch_size = 64, shuffle = True)\n",
    "\n",
    "alphatestloader = DataLoader(alphatestset, batch_size = 64, shuffle = True)\n",
    "betatestloader = DataLoader(betatestset, batch_size = 64, shuffle = True)\n",
    "gammatestloader = DataLoader(gammatestset, batch_size = 64, shuffle = True)\n",
    "deltatestloader = DataLoader(deltatestset, batch_size = 64, shuffle = True)\n",
    "\n",
    "fulltrainloader = DataLoader(fulltrainset, batch_size = 64, shuffle = True)\n",
    "fullvalloader = DataLoader(fullvalset, batch_size = 64, shuffle = True)\n",
    "fulltestloader = DataLoader(fulltestset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define your ANN model\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(19*10001, 5000)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(5000, 300)\n",
    "        self.fc3 = nn.Linear(300,3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 19*10001)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Define hyperparameters\n",
    "hidden_size = 19\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "batch_size = 2\n",
    "\n",
    "# Create DataLoader objects\n",
    "\n",
    "# Initialize the ANN model\n",
    "model = ANN(30001, hidden_size, 3)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss with Logits\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in trainloader:\n",
    "        # Forward pass\n",
    "        inputs = inputs.to(torch.float32)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    # Print average loss for this epoch\n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "# Evaluation\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in testloader:\n",
    "        outputs = model(imgs)\n",
    "        predicted = torch.argmax(outputs, dim=1)\n",
    "        _, labels = torch.max(labels, dim=1)\n",
    "        # print(predicted, labels)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy on test set: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_EEG_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EEG_Classifier, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, 25, 2) \n",
    "        \n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(25)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(4, 4)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(25, 30, 2) \n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(30)\n",
    "        self.fc1 = nn.Linear(28110, 256)\n",
    "        self.fc2 = nn.Linear(256, 3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = F.relu(self.fc1(outconv2))\n",
    "        # print(outfc1.shape)\n",
    "\n",
    "        outfc2 = self.fc2(outfc1)\n",
    "        # print(outfc2.shape)\n",
    "\n",
    "        out = F.softmax(outfc2, dim = 1)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def get_accuracy(model, train=True, train_data = trainloader, val_data = valloader):\n",
    "    if train:\n",
    "        dataloader = train_data\n",
    "    else:\n",
    "        dataloader = val_data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dataloader:\n",
    "            outputs = model(imgs)\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            _, labels = torch.max(labels, dim=1)\n",
    "            # print(predicted, labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return 100 * correct / total\n",
    "torch.manual_seed(5)\n",
    "def train(model,batch_size=8, traindata = trainloader, valdata = valloader, num_epochs=10, rate = 0.001):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=rate, momentum=0.9)\n",
    "    \n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(traindata):\n",
    "            \n",
    "            # print(imgs.shape)\n",
    "            imgs = imgs.to(torch.float32)\n",
    "            out = model(imgs)             # forward pass\n",
    "            # print(out.shape)\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, train=True, train_data = traindata)) # compute training accuracy \n",
    "            val_acc.append(get_accuracy(model, train=False, val_data = valdata))  # compute validation accuracy\n",
    "            n += 1\n",
    "    print(\"Iterations:\", n)\n",
    "    # plotting\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "eegclassifier = CNN_EEG_Classifier()\n",
    "train(eegclassifier, batch_size = 64, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test accuracy:\",get_accuracy(eegclassifier,train = True, train_data = testloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
