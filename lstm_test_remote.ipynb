{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhutanig\\AppData\\Local\\Temp\\ipykernel_1636\\1886153275.py:74: RuntimeWarning: The data contains 'boundary' events, indicating data discontinuities. Be cautious of filtering and epoching around these events.\n",
      "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\utils\\check.py:382\u001b[0m, in \u001b[0;36m_soft_import\u001b[1;34m(name, purpose, strict)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 382\u001b[0m     mod \u001b[39m=\u001b[39m import_module(name)\n\u001b[0;32m    383\u001b[0m     \u001b[39mreturn\u001b[39;00m mod\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pymatreader'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\io\\eeglab\\_eeglab.py:74\u001b[0m, in \u001b[0;36m_readmat\u001b[1;34m(fname, uint16_codec)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     read_mat \u001b[39m=\u001b[39m _import_pymatreader_funcs(\u001b[39m\"\u001b[39;49m\u001b[39mEEGLAB I/O\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     75\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:  \u001b[39m# pymatreader not installed\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\utils\\check.py:175\u001b[0m, in \u001b[0;36m_import_pymatreader_funcs\u001b[1;34m(purpose)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_import_pymatreader_funcs\u001b[39m(purpose):\n\u001b[1;32m--> 175\u001b[0m     pymatreader \u001b[39m=\u001b[39m _soft_import(\u001b[39m\"\u001b[39;49m\u001b[39mpymatreader\u001b[39;49m\u001b[39m\"\u001b[39;49m, purpose)\n\u001b[0;32m    176\u001b[0m     \u001b[39mreturn\u001b[39;00m pymatreader\u001b[39m.\u001b[39mread_mat\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\utils\\check.py:386\u001b[0m, in \u001b[0;36m_soft_import\u001b[1;34m(name, purpose, strict)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m strict:\n\u001b[1;32m--> 386\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    387\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFor \u001b[39m\u001b[39m{\u001b[39;00mpurpose\u001b[39m}\u001b[39;00m\u001b[39m to work, the \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m module is needed, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    388\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbut it could not be imported.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m    390\u001b[0m             (\n\u001b[0;32m    391\u001b[0m                 indent(\n\u001b[0;32m    392\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39muse the following installation method \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    393\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mappropriate for your environment:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    394\u001b[0m                 ),\n\u001b[0;32m    395\u001b[0m                 indent(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpip install \u001b[39m\u001b[39m{\u001b[39;00mpip_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    396\u001b[0m                 indent(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mconda install -c conda-forge \u001b[39m\u001b[39m{\u001b[39;00mpip_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    397\u001b[0m             )\n\u001b[0;32m    398\u001b[0m         )\n\u001b[0;32m    399\u001b[0m     )\n\u001b[0;32m    400\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: For EEGLAB I/O to work, the pymatreader module is needed, but it could not be imported.\n              use the following installation method appropriate for your environment:\n              'pip install pymatreader'\n              'conda install -c conda-forge pymatreader'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mB.Homes$\\bhutanig\\Documents\\EEG-Alzheimer-Detection\\lstm_test_remote.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m     <a href='vscode-notebook-cell://vsrv1/B.Homes%24/bhutanig/Documents/EEG-Alzheimer-Detection/lstm_test_remote.ipynb#W0sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m rawpath \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mVSRV1\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mB.Homes$\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mbhutanig\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDocuments\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mEEG-Alzheimer-Detection\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mRaw Data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msub-\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39meeg\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%\u001b[39m(\u001b[39mstr\u001b[39m(i)\u001b[39m.\u001b[39mzfill(\u001b[39m3\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell://vsrv1/B.Homes%24/bhutanig/Documents/EEG-Alzheimer-Detection/lstm_test_remote.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m file \u001b[39m=\u001b[39m glob\u001b[39m.\u001b[39mglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(rawpath, \u001b[39m'\u001b[39m\u001b[39m*.set\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m---> <a href='vscode-notebook-cell://vsrv1/B.Homes%24/bhutanig/Documents/EEG-Alzheimer-Detection/lstm_test_remote.ipynb#W0sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m raw \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39;49mio\u001b[39m.\u001b[39;49mread_raw_eeglab(file[\u001b[39m0\u001b[39;49m], preload \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell://vsrv1/B.Homes%24/bhutanig/Documents/EEG-Alzheimer-Detection/lstm_test_remote.ipynb#W0sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m \u001b[39m# Update data lists\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell://vsrv1/B.Homes%24/bhutanig/Documents/EEG-Alzheimer-Detection/lstm_test_remote.ipynb#W0sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m data_list[\u001b[39m'\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(raw)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\io\\eeglab\\eeglab.py:332\u001b[0m, in \u001b[0;36mread_raw_eeglab\u001b[1;34m(input_fname, eog, preload, uint16_codec, montage_units, verbose)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39m@fill_doc\u001b[39m\n\u001b[0;32m    289\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_raw_eeglab\u001b[39m(\n\u001b[0;32m    290\u001b[0m     input_fname,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    295\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    296\u001b[0m ):\n\u001b[0;32m    297\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Read an EEGLAB .set file.\u001b[39;00m\n\u001b[0;32m    298\u001b[0m \n\u001b[0;32m    299\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[39m    .. versionadded:: 0.11.0\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 332\u001b[0m     \u001b[39mreturn\u001b[39;00m RawEEGLAB(\n\u001b[0;32m    333\u001b[0m         input_fname\u001b[39m=\u001b[39;49minput_fname,\n\u001b[0;32m    334\u001b[0m         preload\u001b[39m=\u001b[39;49mpreload,\n\u001b[0;32m    335\u001b[0m         eog\u001b[39m=\u001b[39;49meog,\n\u001b[0;32m    336\u001b[0m         uint16_codec\u001b[39m=\u001b[39;49muint16_codec,\n\u001b[0;32m    337\u001b[0m         montage_units\u001b[39m=\u001b[39;49mmontage_units,\n\u001b[0;32m    338\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    339\u001b[0m     )\n",
      "File \u001b[1;32m<decorator-gen-254>:12\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, input_fname, eog, preload, uint16_codec, montage_units, verbose)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\io\\eeglab\\eeglab.py:454\u001b[0m, in \u001b[0;36mRawEEGLAB.__init__\u001b[1;34m(self, input_fname, eog, preload, uint16_codec, montage_units, verbose)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[39m@verbose\u001b[39m\n\u001b[0;32m    443\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    444\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    451\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    452\u001b[0m ):  \u001b[39m# noqa: D102\u001b[39;00m\n\u001b[0;32m    453\u001b[0m     input_fname \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(_check_fname(input_fname, \u001b[39m\"\u001b[39m\u001b[39mread\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39minput_fname\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m--> 454\u001b[0m     eeg \u001b[39m=\u001b[39m _check_load_mat(input_fname, uint16_codec)\n\u001b[0;32m    455\u001b[0m     \u001b[39mif\u001b[39;00m eeg\u001b[39m.\u001b[39mtrials \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    456\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    457\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe number of trials is \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. It must be 1 for raw\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    458\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m files. Please use `mne.io.read_epochs_eeglab` if\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m the .set file contains epochs.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m eeg\u001b[39m.\u001b[39mtrials\n\u001b[0;32m    460\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\io\\eeglab\\eeglab.py:78\u001b[0m, in \u001b[0;36m_check_load_mat\u001b[1;34m(fname, uint16_codec)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_load_mat\u001b[39m(fname, uint16_codec):\n\u001b[0;32m     77\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check if the mat struct contains 'EEG'.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m     eeg \u001b[39m=\u001b[39m _readmat(fname, uint16_codec\u001b[39m=\u001b[39;49muint16_codec)\n\u001b[0;32m     79\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mALLEEG\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m eeg:\n\u001b[0;32m     80\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[0;32m     81\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mLoading an ALLEEG array is not supported. Please contact\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     82\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mmne-python developers for more information.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     83\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\mne\\io\\eeglab\\_eeglab.py:76\u001b[0m, in \u001b[0;36m_readmat\u001b[1;34m(fname, uint16_codec)\u001b[0m\n\u001b[0;32m     74\u001b[0m     read_mat \u001b[39m=\u001b[39m _import_pymatreader_funcs(\u001b[39m\"\u001b[39m\u001b[39mEEGLAB I/O\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:  \u001b[39m# pymatreader not installed\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     eeg \u001b[39m=\u001b[39m loadmat(fname, squeeze_me\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, mat_dtype\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_for_scipy_mat_struct(eeg)\n\u001b[0;32m     78\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\io\\matlab\\_mio.py:227\u001b[0m, in \u001b[0;36mloadmat\u001b[1;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    226\u001b[0m     MR, _ \u001b[39m=\u001b[39m mat_reader_factory(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 227\u001b[0m     matfile_dict \u001b[39m=\u001b[39m MR\u001b[39m.\u001b[39;49mget_variables(variable_names)\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m mdict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     mdict\u001b[39m.\u001b[39mupdate(matfile_dict)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\io\\matlab\\_mio5.py:330\u001b[0m, in \u001b[0;36mMatFile5Reader.get_variables\u001b[1;34m(self, variable_names)\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 330\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_var_array(hdr, process)\n\u001b[0;32m    331\u001b[0m \u001b[39mexcept\u001b[39;00m MatReadError \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    332\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    333\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUnreadable variable \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m, because \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m    334\u001b[0m         \u001b[39mWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\scipy\\io\\matlab\\_mio5.py:290\u001b[0m, in \u001b[0;36mMatFile5Reader.read_var_array\u001b[1;34m(self, header, process)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_var_array\u001b[39m(\u001b[39mself\u001b[39m, header, process\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m    274\u001b[0m \u001b[39m    \u001b[39m\u001b[39m''' Read array, given `header`\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[39m       `process`.\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 290\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_matrix_reader\u001b[39m.\u001b[39;49marray_from_header(header, process)\n",
      "File \u001b[1;32m_mio5_utils.pyx:665\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio5_utils.pyx:734\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio_utils.pyx:11\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio_utils.squeeze_element\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_mio_utils.pyx:18\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio_utils.squeeze_element\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\numpy\\core\\fromnumeric.py:1487\u001b[0m, in \u001b[0;36m_squeeze_dispatcher\u001b[1;34m(a, axis)\u001b[0m\n\u001b[0;32m   1482\u001b[0m     a \u001b[39m=\u001b[39m concatenate((a,) \u001b[39m*\u001b[39m repeats)[:new_size]\n\u001b[0;32m   1484\u001b[0m     \u001b[39mreturn\u001b[39;00m reshape(a, new_shape)\n\u001b[1;32m-> 1487\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_squeeze_dispatcher\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1488\u001b[0m     \u001b[39mreturn\u001b[39;00m (a,)\n\u001b[0;32m   1491\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_squeeze_dispatcher)\n\u001b[0;32m   1492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msqueeze\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import glob\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import *\n",
    "import gc\n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import ICA, corrmap, create_ecg_epochs, create_eog_epochs\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Filtering functions\n",
    "def butter_bandpass(lowcut, highcut, fs, order=6):\n",
    "  return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=6):\n",
    "  b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "  y = lfilter(b, a, data)\n",
    "  return y\n",
    "def calcsnr(prefilter, filtered):\n",
    "  filteredsum = 0\n",
    "  denomsum = 0\n",
    "  for i in range(len(prefilter)):\n",
    "    filteredsum = filteredsum+filtered[i]*filtered[i]\n",
    "    denomsum = denomsum+ (filtered[i]-prefilter[i])*(filtered[i]-prefilter[i])\n",
    "  return 10*math.log10(filteredsum/denomsum)\n",
    "\n",
    "# Custom dataset object\n",
    "class EEGDataset(Dataset):\n",
    "  def __init__(self, eeglist, labels, transform=None, target_transform=None):\n",
    "    self.labels = torch.from_numpy(np.array(labels))\n",
    "    self.labels = self.labels.to(torch.float32)\n",
    "    self.eeglist = eeglist\n",
    "    self.transform = transform\n",
    "    self.target_transform = target_transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "\n",
    "    label = self.labels[idx]\n",
    "    raw = self.eeglist[idx]\n",
    "    eeg = torch.from_numpy(raw.get_data())\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "    if self.target_transform:\n",
    "      label = self.target_transform(label)\n",
    "    return eeg, label\n",
    "\n",
    "# Collect Raw objects from MNE in Python lists\n",
    "data_list = {\"raw\":[], \"preprocessed\":[], \"manual_preprocess\":[], \"rawsample\": [], \"preprocessedsample\":[], \"manual_preprocesssample\":[]}\n",
    "labels = []\n",
    "\n",
    "# Get subject information\n",
    "readtsv = pd.read_csv('participants.tsv', sep = '\\t')\n",
    "\n",
    "# Channel names, taken from OpenNeuro\n",
    "channel_names = ['Fp1', 'Fp2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4', 'T5', 'T6', 'Fz', 'Cz', 'Pz']\n",
    "\n",
    "# Parse in .set files\n",
    "for i in range(1,89):\n",
    "\n",
    "  filteredpath = r\"\\\\VSRV1\\B.Homes$\\bhutanig\\Documents\\EEG-Alzheimer-Detection\\OpenNeuro Preprocessed\\sub-%s\\eeg\"%(str(i).zfill(3))\n",
    "  filteredfile = glob.glob(os.path.join(filteredpath, '*.set'))\n",
    "  filtered = mne.io.read_raw_eeglab(filteredfile[0], preload = True)\n",
    "\n",
    "  rawpath = r\"\\\\VSRV1\\B.Homes$\\bhutanig\\Documents\\EEG-Alzheimer-Detection\\Raw Data\\sub-%s\\eeg\"%(str(i).zfill(3))\n",
    "  file = glob.glob(os.path.join(rawpath, '*.set'))\n",
    "  raw = mne.io.read_raw_eeglab(file[0], preload = True)\n",
    "\n",
    "  # Update data lists\n",
    "  data_list['raw'].append(raw)\n",
    "  data_list['preprocessed'].append(filtered)\n",
    "\n",
    "  label = readtsv['Group'][i-1]\n",
    "  # Change labels to onehot encodings\n",
    "  if label == 'A':\n",
    "    labels.append([0,0,1])\n",
    "  elif label == 'F':\n",
    "    labels.append([0,1,0])\n",
    "  elif label == 'C':\n",
    "    labels.append([1,0,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne_icalabel import label_components\n",
    "exclusion = ['line noise', 'heartbeat', 'eye blink']\n",
    "\n",
    "def manual_process(raw, plotting = True):\n",
    "    freq_low = 0.5\n",
    "    freq_high = 45\n",
    "    iirparams = dict(order = 4, ftype = 'butter')\n",
    "\n",
    "    raw.filter(freq_low, freq_high, method = 'iir', iir_params = iirparams)\n",
    "\n",
    "    # Create ICA object and fit it to the data\n",
    "    ica = ICA(n_components=19, random_state=97, verbose = False)\n",
    "    ica.fit(raw)\n",
    "\n",
    "    # Plot ICA components to identify artifacts\n",
    "    icalabels = label_components(raw, ica, method = 'iclabel')\n",
    "    if plotting == True:\n",
    "        ica.plot_components()\n",
    "        picks = list(range(0,18))\n",
    "        ica.plot_properties(raw, picks=picks)\n",
    "        print(icalabels)\n",
    "    ica.exclude = []\n",
    "    for i, label in enumerate(icalabels):\n",
    "        if label in exclusion:\n",
    "            ica.exclude.append(i)\n",
    "    ica.apply(raw)\n",
    "            \n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output \n",
    "i = 0\n",
    "for subject in data_list['raw']:\n",
    "    raw = subject.copy().load_data()\n",
    "    data_list['manual_preprocess'].append(manual_process(raw, plotting = False))\n",
    "    clear_output()\n",
    "    i+=1\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "totals = [485.5, 276.5, 402]\n",
    "trainlist, vallist, testlist, trainlabels, vallabels, testlabels = [],[],[],[],[],[]\n",
    "labelonehot = [[0,0,1], [0,1,0], [1,0,0]]\n",
    "#make sure enough of each group in each partition of data\n",
    "for x, label in enumerate(labelonehot):\n",
    "  count = 0\n",
    "  for i in range (len(labels)):\n",
    "    if labels[i] == label:\n",
    "      m = 0\n",
    "      # print(len(n.get_data()[0]))\n",
    "      while 15000*(m+1) < len(data_list['manual_preprocess'][i].copy().get_data()[0]):\n",
    "        if totals[x]*2-count>120:\n",
    "          n = data_list['manual_preprocess'][i].copy()\n",
    "          trainlist.append(n.crop(m*30,(m+1)*30))\n",
    "          trainlabels.append(labels[i])\n",
    "        if totals[x]*2-count>40:\n",
    "          n = data_list['manual_preprocess'][i].copy()\n",
    "          vallist.append(n.crop(m*30,(m+1)*30))\n",
    "          vallabels.append(labels[i])\n",
    "        else:\n",
    "          n = data_list['manual_preprocess'][i].copy()\n",
    "          testlist.append(n.crop(m*30, (m+1)*30))\n",
    "          testlabels.append(labels[i])\n",
    "        count = count + 1\n",
    "        m = m+1\n",
    "\n",
    "\n",
    "trainset = EEGDataset(trainlist, trainlabels)\n",
    "valset = EEGDataset(vallist, vallabels)\n",
    "testset = EEGDataset(testlist, testlabels)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = 127, shuffle = True)\n",
    "valloader = DataLoader(valset, batch_size = 127, shuffle = True)\n",
    "testloader = DataLoader(testset, batch_size = 127, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CNN_EEG_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EEG_Classifier, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, 25, 2) \n",
    "        \n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(25)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(4, 4)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(25, 30, 2) \n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(30)\n",
    "        self.fc1 = nn.Linear(28110, 256)\n",
    "        self.fc2 = nn.Linear(256, 3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = F.relu(self.fc1(outconv2))\n",
    "        # print(outfc1.shape)\n",
    "\n",
    "        outfc2 = self.fc2(outfc1)\n",
    "        # print(outfc2.shape)\n",
    "\n",
    "        out = F.softmax(outfc2, dim = 1)\n",
    "        print(out.shape)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CNN_EEG_Classifier_lstm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EEG_Classifier_lstm, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, 25, 2) \n",
    "        \n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(25)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(4, 4)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(25, 30, 2) \n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(30)\n",
    "\n",
    "        self.hidden_size = 100\n",
    "        self.lstm = nn.LSTM(30, self.hidden_size, 1, batch_first = True)\n",
    "\n",
    "        self.fc1 = nn.Linear(28110, 256)\n",
    "        self.fc2 = nn.Linear(256, 3)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        # print(x.shape, h0.shape, c0.shape)\n",
    "        outlstm = outconv2.permute(0, 2, 1)\n",
    "        outlstm, _ = self.lstm(outlstm, (h0, c0))\n",
    "        outlstm = outlstm[:, -1, :]\n",
    "        outlstm = outlstm.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = F.relu(self.fc1(outlstm))\n",
    "\n",
    "        # print(outfc1.shape)\n",
    "\n",
    "        outfc2 = self.fc2(outfc1)\n",
    "        # print(outfc2.shape)\n",
    "\n",
    "        out = F.softmax(outfc2, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CNN_EEG_Classifier_dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EEG_Classifier_dropout, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, 25, 2) \n",
    "        \n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(25)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(4, 4)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(25, 30, 2) \n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(30)\n",
    "\n",
    "        self.fc1 = nn.Linear(28110, 10000)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(10000, 1000)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout3 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = self.dropout1(F.relu(self.fc1(outconv2)))\n",
    "\n",
    "        # print(outfc1.shape)\n",
    "\n",
    "        outfc2 = self.dropout2(self.fc2(outfc1))\n",
    "        # print(outfc2.shape)\n",
    "\n",
    "        outfc3 = self.dropout3(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CNN_EEG_Classifier_linear1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_EEG_Classifier_linear1, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, 25, 2) \n",
    "        \n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(25)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(4, 4)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(25, 30, 2) \n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(30)\n",
    "\n",
    "        self.fc1 = nn.Linear(28110, 10000)\n",
    "        self.fc2 = nn.Linear(10000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv2)))\n",
    "\n",
    "        # print(outfc1.shape)\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "        # print(outfc2.shape)\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "class CNN_EEG_Classifier_linear2(nn.Module):\n",
    "    def __init__(self, conv1_kernel_size = 2, conv2_kernel_size = 2, conv1_size = 25, conv2_size = 30, pool_kernel = 2, pool_stride = 2, conv1_stride = 1, conv2_stride = 1):\n",
    "        \"\"\"Average Pool, Pool size 2\"\"\"\n",
    "        super(CNN_EEG_Classifier_linear2, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, conv1_size, conv1_kernel_size) \n",
    "        size1 = ((15001-conv1_kernel_size)/conv1_stride) + 1\n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(conv1_size)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.AvgPool1d(pool_kernel, pool_stride)\n",
    "        size1_pool = ((size1 - pool_kernel)/pool_stride) + 1\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv1_size, conv2_size, conv2_kernel_size) \n",
    "        size2 = ((size1_pool-conv2_kernel_size)/conv2_stride) + 1\n",
    "        size2_pool = ((size2 - pool_kernel)//pool_stride) + 1\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(conv2_size)\n",
    "\n",
    "        size1_flatten = size2_pool*conv2_size\n",
    "        linear1_size = int(size1_flatten)\n",
    "\n",
    "        self.fc1 = nn.Linear(linear1_size, 10000)\n",
    "        self.fc2 = nn.Linear(10000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "        # print(outconv2.shape)\n",
    "        outfc1 = (F.relu(self.fc1(outconv2)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_EEG_Classifier_linear3(nn.Module):\n",
    "    def __init__(self, conv1_kernel_size = 2, conv2_kernel_size = 2, conv1_size = 25, conv2_size = 30, pool_kernel = 2, pool_stride = 2, conv1_stride = 1, conv2_stride = 1):\n",
    "        \"\"\"Max Pool, Pool size 2\"\"\"\n",
    "        super(CNN_EEG_Classifier_linear3, self).__init__()\n",
    "        #USE LARGER KERNEL BECAUSE IMAGES ARE HIGH RESOLUTION, FEATURES TAKE UP MORE PIXELS\n",
    "        self.conv1 = nn.Conv1d(19, conv1_size, conv1_kernel_size) \n",
    "        size1 = ((15001-conv1_kernel_size)/conv1_stride) + 1\n",
    "        #BATCH NORMALIZATION TO PREVENT VANISHING GRADIENTS\n",
    "        self.bn1 = nn.BatchNorm1d(conv1_size)\n",
    "        #LARGE POOLING KERNEL TO REDUCE DIMENSIONALIZATION FASTER (JUST FOUND THIS TO BE HELPFUL BY EXPERIMENTING)\n",
    "        self.pool = nn.MaxPool1d(pool_kernel, pool_stride)\n",
    "        size1_pool = ((size1 - pool_kernel)/pool_stride) + 1\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv1_size, conv2_size, conv2_kernel_size) \n",
    "        size2 = ((size1_pool-conv2_kernel_size)/conv2_stride) + 1\n",
    "        size2_pool = ((size2 - pool_kernel)//pool_stride) + 1\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(conv2_size)\n",
    "\n",
    "        size1_flatten = size2_pool*conv2_size\n",
    "        linear1_size = int(size1_flatten)\n",
    "\n",
    "        self.fc1 = nn.Linear(linear1_size, 10000)\n",
    "        self.fc2 = nn.Linear(10000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv2 = outconv2.view(batch_size, -1)\n",
    "        # print(outconv2.shape)\n",
    "        outfc1 = (F.relu(self.fc1(outconv2)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_LSTM_EEG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LSTM_EEG, self).__init__()\n",
    "        # This is taking in 64 channels from what I understand, we could change it to 19\n",
    "        self.conv1 = nn.Conv1d(19, 64, kernel_size = 3, stride = 1)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size = 3, stride = 1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        # self.conv1 = nn.Conv2d(1, 64, kernel_size = (1,3), stride = 1)\n",
    "        # self.conv2 = nn.Conv2d(64, 64, kernel_size = (1, 3), stride = 1)\n",
    "        # print(\"SHAPE =\", self.conv1.weight.shape)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.pool = nn.MaxPool1d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        self.flatten = nn.Flatten() # Rad removed this line\n",
    "        self.hidden_size = 100\n",
    "        self.lstm = nn.LSTM(64, self.hidden_size, 1, batch_first = True)\n",
    "        \n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(100, 100)\n",
    "        self.dropout3 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.dropout4 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        # print(x.shape)\n",
    "        x = (self.pool(self.dropout1(F.relu(self.bn1(self.conv2(x))))))\n",
    "        # print(x.shape)\n",
    "        # x = self.flatten(x)\n",
    "        # print(x.shape)\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size)\n",
    "        # print(x.shape, h0.shape, c0.shape)\n",
    "        print(x.shape)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        print(x.shape)\n",
    "        x = self.dropout2(x[:, -1, :])\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc2(F.relu(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = self.fc3(F.sigmoid(x))\n",
    "        print(x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "class CNN_EEG_Classifier_linear_cnn_extra(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"MORE CNNs, MORE LAYERS, MORE POWER\"\"\"\n",
    "        super(CNN_EEG_Classifier_linear_cnn_extra, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35, 40, 50]\n",
    "        conv_stride = [1, 1, 1, 1, 1]\n",
    "        conv_kernel_size = [2, 2, 2, 2, 2]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = 4\n",
    "        pool_stride = 4\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.conv4 = nn.Conv1d(conv_size[2], conv_size[3], conv_kernel_size[3], conv_stride[3])\n",
    "        self.bn4 = nn.BatchNorm1d(conv_size[3])\n",
    "        self.conv5 = nn.Conv1d(conv_size[3], conv_size[4], conv_kernel_size[4], conv_stride[4])\n",
    "        self.bn5 = nn.BatchNorm1d(conv_size[4])\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(pool_kernel, pool_stride)\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel)//pool_stride) + 1  \n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        outconv3 = self.pool(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        outconv4 = self.pool(F.relu(self.bn4(self.conv4(outconv3))))\n",
    "        outconv5 = self.pool(F.relu(self.bn5(self.conv5(outconv4))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv5 = outconv5.view(batch_size, -1)\n",
    "        # print(outconv2.shape)\n",
    "        outfc1 = (F.relu(self.fc1(outconv2)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNN_EEG_Classifier_linear_cnn_extra_pool_less(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"MORE CNNs, MORE LAYERS, MORE POWER\"\"\"\n",
    "        super(CNN_EEG_Classifier_linear_cnn_extra_pool_less, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35, 40, 50]\n",
    "        conv_stride = [1, 1, 1, 1, 1]\n",
    "        conv_kernel_size = [2, 2, 2, 2, 2]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [4, 1, 4, 1, 4]\n",
    "        pool_stride = [4, 1, 4, 1, 4]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "\n",
    "        self.conv4 = nn.Conv1d(conv_size[2], conv_size[3], conv_kernel_size[3], conv_stride[3])\n",
    "        self.bn4 = nn.BatchNorm1d(conv_size[3])\n",
    "        self.pool4 = nn.MaxPool1d(pool_kernel[3], pool_stride[3])\n",
    "\n",
    "        self.conv5 = nn.Conv1d(conv_size[3], conv_size[4], conv_kernel_size[4], conv_stride[4])\n",
    "        self.bn5 = nn.BatchNorm1d(conv_size[4])\n",
    "        self.pool5 = nn.MaxPool1d(pool_kernel[4], pool_stride[4])\n",
    "        \n",
    "        \n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv4 = self.pool4(F.relu(self.bn4(self.conv4(outconv3))))\n",
    "        # print(outconv4.shape)\n",
    "        outconv5 = self.pool5(F.relu(self.bn5(self.conv5(outconv4))))\n",
    "        # print(outconv5.shape)\n",
    "        outconv5 = outconv5.view(batch_size, -1)\n",
    "        # print(outconv5.shape)\n",
    "        outfc1 = (F.relu(self.fc1(outconv5)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class CNN_EEG_Classifier_3cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"MORE CNNs, MORE LAYERS, MORE POWER\n",
    "        That was a lie\"\"\"\n",
    "        super(CNN_EEG_Classifier_3cnn, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35]\n",
    "        conv_stride = [1, 1, 1]\n",
    "        conv_kernel_size = [2, 2, 2]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1]\n",
    "        pool_stride = [1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 7500)\n",
    "        self.fc2 = nn.Linear(7500, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv3 = outconv3.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv3)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "class CNN_EEG_Classifier_3cnn_high_kernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"MORE CNNs, MORE LAYERS, MORE POWER\n",
    "        That was a lie\"\"\"\n",
    "        super(CNN_EEG_Classifier_3cnn_high_kernel, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35]\n",
    "        conv_stride = [1, 1, 1]\n",
    "        conv_kernel_size = [4, 4, 4]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1]\n",
    "        pool_stride = [1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 7500)\n",
    "        self.fc2 = nn.Linear(7500, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv3 = outconv3.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv3)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_EEG_Classifier_10cnn_mix_kernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"MORE CNNs, MORE LAYERS, MORE POWER\n",
    "        That was a lie\n",
    "        Still, trying 10 CNNs because I am dumb\"\"\"\n",
    "        super(CNN_EEG_Classifier_10cnn_mix_kernel, self).__init__()\n",
    "\n",
    "        conv_size = [25, 30, 35, 40, 45, 50, 55, 60, 65, 70]\n",
    "        conv_stride = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "        conv_kernel_size = [2, 3, 2, 3, 2, 3, 2, 3, 2, 3]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1, 1, 1, 1, 1, 1, 4, 1]\n",
    "        pool_stride = [1, 4, 1, 1, 1, 1, 1, 1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        self.conv4 = nn.Conv1d(conv_size[2], conv_size[3], conv_kernel_size[3], conv_stride[3])\n",
    "        self.bn4 = nn.BatchNorm1d(conv_size[3])\n",
    "        self.pool4 = nn.MaxPool1d(pool_kernel[3], pool_stride[3])\n",
    "        \n",
    "        self.conv5 = nn.Conv1d(conv_size[3], conv_size[4], conv_kernel_size[4], conv_stride[4])\n",
    "        self.bn5 = nn.BatchNorm1d(conv_size[4])\n",
    "        self.pool5 = nn.MaxPool1d(pool_kernel[4], pool_stride[4])\n",
    "        \n",
    "        self.conv6 = nn.Conv1d(conv_size[4], conv_size[5], conv_kernel_size[5], conv_stride[5])\n",
    "        self.bn6 = nn.BatchNorm1d(conv_size[5])\n",
    "        self.pool6 = nn.MaxPool1d(pool_kernel[5], pool_stride[5])\n",
    "        \n",
    "        self.conv7 = nn.Conv1d(conv_size[5], conv_size[6], conv_kernel_size[6], conv_stride[6])\n",
    "        self.bn7 = nn.BatchNorm1d(conv_size[6])\n",
    "        self.pool7 = nn.MaxPool1d(pool_kernel[6], pool_stride[6])\n",
    "        \n",
    "        self.conv8 = nn.Conv1d(conv_size[6], conv_size[7], conv_kernel_size[7], conv_stride[7])\n",
    "        self.bn8 = nn.BatchNorm1d(conv_size[7])\n",
    "        self.pool8 = nn.MaxPool1d(pool_kernel[7], pool_stride[7])\n",
    "        \n",
    "        self.conv9 = nn.Conv1d(conv_size[7], conv_size[8], conv_kernel_size[8], conv_stride[8])\n",
    "        self.bn9 = nn.BatchNorm1d(conv_size[8])\n",
    "        self.pool9 = nn.MaxPool1d(pool_kernel[8], pool_stride[8])\n",
    "        \n",
    "        self.conv10 = nn.Conv1d(conv_size[8], conv_size[9], conv_kernel_size[9], conv_stride[9])\n",
    "        self.bn10 = nn.BatchNorm1d(conv_size[9])\n",
    "        self.pool10 = nn.MaxPool1d(pool_kernel[9], pool_stride[9])\n",
    "        \n",
    "\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 5000)\n",
    "        self.fc2 = nn.Linear(5000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv4 = self.pool4(F.relu(self.bn4(self.conv4(outconv3))))\n",
    "        # print(outconv4.shape)\n",
    "        outconv5 = self.pool5(F.relu(self.bn5(self.conv5(outconv4))))\n",
    "        outconv6 = self.pool6(F.relu(self.bn6(self.conv6(outconv5))))\n",
    "        outconv7 = self.pool7(F.relu(self.bn7(self.conv7(outconv6))))\n",
    "        outconv8 = self.pool8(F.relu(self.bn8(self.conv8(outconv7))))\n",
    "        outconv9 = self.pool9(F.relu(self.bn9(self.conv9(outconv8))))\n",
    "        outconv10 = self.pool10(F.relu(self.bn10(self.conv10(outconv9))))\n",
    "        \n",
    "        outconv10 = outconv10.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv10)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_EEG_Classifier_3cnn_medium_kernel(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Trying kernel size 3 with 3 CNN model\"\"\"\n",
    "        super(CNN_EEG_Classifier_3cnn_medium_kernel, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35]\n",
    "        conv_stride = [1, 1, 1]\n",
    "        conv_kernel_size = [3, 3, 3]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1]\n",
    "        pool_stride = [1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 7500)\n",
    "        self.fc2 = nn.Linear(7500, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv3 = outconv3.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv3)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_EEG_Classifier_3cnn_medium_kernel_leaky(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Trying kernel size 3 with 3 CNN model with leakyReLU\"\"\"\n",
    "        super(CNN_EEG_Classifier_3cnn_medium_kernel_leaky, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35]\n",
    "        conv_stride = [1, 1, 1]\n",
    "        conv_kernel_size = [3, 3, 3]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1]\n",
    "        pool_stride = [1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 7500)\n",
    "        self.fc2 = nn.Linear(7500, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.leaky_relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.leaky_relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.leaky_relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv3 = outconv3.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.leaky_relu(self.fc1(outconv3)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.leaky_relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class CNN_EEG_Classifier_3cnn_medium_kernel_stride(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"Trying stride 3 with 3 CNN model, 3 CNN kernel size\"\"\"\n",
    "        super(CNN_EEG_Classifier_3cnn_medium_kernel_stride, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35]\n",
    "        conv_stride = [3, 3, 3]\n",
    "        conv_kernel_size = [3, 3, 3]\n",
    "        n_layers = len(conv_size)\n",
    "        \n",
    "        pool_kernel = [1, 4, 1]\n",
    "        pool_stride = [1, 4, 1]\n",
    "        \n",
    "        \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 500)\n",
    "        self.fc3 = nn.Linear(500, 100)\n",
    "        self.dropout1 = nn.Dropout(0.75)\n",
    "        self.fc4 = nn.Linear(100, 3)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv3 = outconv3.view(batch_size, -1)\n",
    "\n",
    "        outfc1 = (F.relu(self.fc1(outconv3)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = self.dropout1(F.relu(self.fc3(outfc2)))\n",
    "        outfc4 = self.fc4(outfc3)\n",
    "        out = F.softmax(outfc4, dim = 1)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNN_EEG_Classifier_best1_5cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"BEST MODEL ATTEMPT 1: 20 epochs 64 batch size, 3 linear layers, learning rate 0.1, maxpool TBD (thinking 2), 5 CNN, kernel stride 2, kernel size 4, 1 dropout 50%\"\"\"\n",
    "        super(CNN_EEG_Classifier_best1_5cnn, self).__init__()\n",
    "        \n",
    "        \n",
    "        conv_size = [25, 30, 35, 40, 45]\n",
    "        conv_stride = [2, 2, 2, 2, 2]\n",
    "        conv_kernel_size = [4, 4, 4, 4, 4]\n",
    "        n_layers = len(conv_size)\n",
    "\n",
    "        pool_kernel = [4, 1, 1, 1, 4]\n",
    "        pool_stride = [4, 1, 1, 1, 4]\n",
    "                \n",
    "        self.conv1 = nn.Conv1d(19, conv_size[0], conv_kernel_size[0], conv_stride[0])\n",
    "        self.bn1 = nn.BatchNorm1d(conv_size[0])\n",
    "        self.pool1 = nn.MaxPool1d(pool_kernel[0], pool_stride[0])\n",
    "\n",
    "        self.conv2 = nn.Conv1d(conv_size[0], conv_size[1], conv_kernel_size[1], conv_stride[1])\n",
    "        self.bn2 = nn.BatchNorm1d(conv_size[1])\n",
    "        self.pool2 = nn.MaxPool1d(pool_kernel[1], pool_stride[1])\n",
    "\n",
    "        self.conv3 = nn.Conv1d(conv_size[1], conv_size[2], conv_kernel_size[2], conv_stride[2])\n",
    "        self.bn3 = nn.BatchNorm1d(conv_size[2])\n",
    "        self.pool3 = nn.MaxPool1d(pool_kernel[2], pool_stride[2])\n",
    "\n",
    "        self.conv4 = nn.Conv1d(conv_size[2], conv_size[3], conv_kernel_size[3], conv_stride[3])\n",
    "        self.bn4 = nn.BatchNorm1d(conv_size[3])\n",
    "        self.pool4 = nn.MaxPool1d(pool_kernel[3], pool_stride[3])\n",
    "\n",
    "        self.conv5 = nn.Conv1d(conv_size[3], conv_size[4], conv_kernel_size[4], conv_stride[4])\n",
    "        self.bn5 = nn.BatchNorm1d(conv_size[4])\n",
    "        self.pool5 = nn.MaxPool1d(pool_kernel[4], pool_stride[4])\n",
    "        \n",
    "        \n",
    "        \n",
    "        size = 15001\n",
    "        for i in range(n_layers):\n",
    "            size = ((size-conv_kernel_size[i])/conv_stride[i]) + 1\n",
    "            size = ((size - pool_kernel[i])//pool_stride[i]) + 1  \n",
    "            # print(size)\n",
    "        \n",
    "        linear1_size = int(size*conv_size[n_layers-1])\n",
    "        # print(linear1_size)\n",
    "        self.fc1 = nn.Linear(linear1_size, 500)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(500, 150)\n",
    "        self.fc3 = nn.Linear(150, 3)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        batch_size = x.shape[0]\n",
    "        outconv1 = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        # print(outconv1.shape)\n",
    "        outconv2 = self.pool2(F.relu(self.bn2(self.conv2(outconv1))))\n",
    "        # print(outconv2.shape)\n",
    "        outconv3 = self.pool3(F.relu(self.bn3(self.conv3(outconv2))))\n",
    "        # print(outconv3.shape)\n",
    "        outconv4 = self.pool4(F.relu(self.bn4(self.conv4(outconv3))))\n",
    "        # print(outconv4.shape)\n",
    "        outconv5 = self.pool5(F.relu(self.bn5(self.conv5(outconv4))))\n",
    "        # print(outconv5.shape)\n",
    "        outconv5 = outconv5.view(batch_size, -1)\n",
    "        # print(outconv5.shape)\n",
    "        outfc1 = self.dropout1(F.relu(self.fc1(outconv5)))\n",
    "\n",
    "        outfc2 = (self.fc2(outfc1))\n",
    "\n",
    "        outfc3 = F.relu(self.fc3(outfc2))\n",
    "        \n",
    "        out = F.softmax(outfc3, dim = 1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def get_accuracy(model, train=True, train_data = trainloader, val_data = valloader):\n",
    "    if train:\n",
    "        dataloader = train_data\n",
    "    else:\n",
    "        dataloader = val_data\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in dataloader:\n",
    "            outputs = model(imgs.float())\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            _, labels = torch.max(labels, dim=1)\n",
    "            # print(predicted, labels)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return 100 * correct / total\n",
    "torch.manual_seed(5)\n",
    "def train_old(model, batch_size=1, traindata = trainloader, valdata = valloader, num_epochs=10, rate = 0.001, name = \"CNN\"):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=rate, momentum=0.9)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(traindata):\n",
    "\n",
    "            # print(imgs.shape)\n",
    "            imgs = imgs.to(torch.float32)\n",
    "            out = model(imgs)             # forward pass\n",
    "            # print(out.shape)\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, train=True, train_data=traindata)) # compute training accuracy\n",
    "            val_acc.append(get_accuracy(model, train=False, val_data = valdata))  # compute validation accuracy\n",
    "            n += 1\n",
    "            print(\"Iteration:\", n)\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"Training Accuracy:\", get_accuracy(model, train=True, train_data=traindata))\n",
    "        print(\"Validation Accuracy:\", get_accuracy(model, train=False, val_data = valdata))\n",
    "            \n",
    "    print(\"Iterations:\", n)\n",
    "    # plotting\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.savefig(\"Accuracy Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "\n",
    "def train_adam_ce(model, batch_size=1, traindata = trainloader, valdata = valloader, num_epochs=10, rate = 0.001, name = \"CNN\"):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=rate)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(traindata):\n",
    "\n",
    "            # print(imgs.shape)\n",
    "            imgs = imgs.to(torch.float32)\n",
    "            out = model(imgs)             # forward pass\n",
    "            # print(out.shape)\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, train=True, train_data=traindata)) # compute training accuracy\n",
    "            val_acc.append(get_accuracy(model, train=False, val_data = valdata))  # compute validation accuracy\n",
    "            n += 1\n",
    "            print(\"Iteration:\", n)\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"Training Accuracy:\", get_accuracy(model, train=True, train_data=traindata))\n",
    "        print(\"Validation Accuracy:\", get_accuracy(model, train=False, val_data = valdata))\n",
    "            \n",
    "    print(\"Iterations:\", n)\n",
    "    # plotting\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.savefig(\"Accuracy Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "\n",
    "def train_adam_ce_step_lr(model, batch_size=1, traindata = trainloader, valdata = valloader, num_epochs=10, rate = 0.001, name = \"CNN\"):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=rate)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(traindata):\n",
    "\n",
    "            if epoch < num_epochs//3:\n",
    "                rate = rate\n",
    "            elif epoch < 2*num_epochs//3:\n",
    "                rate = rate/10\n",
    "            else:\n",
    "                rate = rate/100  \n",
    "            print(\"Rate:\", rate)         \n",
    "\n",
    "            # print(imgs.shape)\n",
    "            imgs = imgs.to(torch.float32)\n",
    "            out = model(imgs)             # forward pass\n",
    "            # print(out.shape)\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, train=True, train_data=traindata)) # compute training accuracy\n",
    "            val_acc.append(get_accuracy(model, train=False, val_data = valdata))  # compute validation accuracy\n",
    "            n += 1\n",
    "            print(\"Iteration:\", n)\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"Training Accuracy:\", get_accuracy(model, train=True, train_data=traindata))\n",
    "        print(\"Validation Accuracy:\", get_accuracy(model, train=False, val_data = valdata))\n",
    "            \n",
    "    print(\"Iterations:\", n)\n",
    "    # plotting\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.savefig(\"Accuracy Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "\n",
    "def train_adam_ce_lin_lr(model, batch_size=1, traindata = trainloader, valdata = valloader, num_epochs=10, rate = 0.001, name = \"CNN\"):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=rate)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    # training\n",
    "    n = 0 # the number of iterations\n",
    "    for epoch in range(num_epochs):\n",
    "        for imgs, labels in iter(traindata):\n",
    "\n",
    "            lr_rate = rate/num_epochs\n",
    "            rate = lr_rate*(num_epochs - epoch)\n",
    "            print(\"Rate:\", rate)\n",
    "\n",
    "            # print(imgs.shape)\n",
    "            imgs = imgs.to(torch.float32)\n",
    "            out = model(imgs)             # forward pass\n",
    "            # print(out.shape)\n",
    "            loss = criterion(out, labels) # compute the total loss\n",
    "            loss.backward()               # backward pass (compute parameter updates)\n",
    "\n",
    "            optimizer.step()              # make the updates for each parameter\n",
    "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
    "\n",
    "            # save the current training information\n",
    "            iters.append(n)\n",
    "            losses.append(float(loss)/batch_size)             # compute *average* loss\n",
    "            train_acc.append(get_accuracy(model, train=True, train_data=traindata)) # compute training accuracy\n",
    "            val_acc.append(get_accuracy(model, train=False, val_data = valdata))  # compute validation accuracy\n",
    "            n += 1\n",
    "            print(\"Iteration:\", n)\n",
    "        print(\"Epoch:\", epoch)\n",
    "        print(\"Training Accuracy:\", get_accuracy(model, train=True, train_data=traindata))\n",
    "        print(\"Validation Accuracy:\", get_accuracy(model, train=False, val_data = valdata))\n",
    "            \n",
    "    print(\"Iterations:\", n)\n",
    "    # plotting\n",
    "    plt.title(\"Loss\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(\"Loss Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.plot(iters, train_acc, label=\"Train\")\n",
    "    plt.plot(iters, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.savefig(\"Accuracy Curve batch %d epochs %d learning rate %f %s model.png\"%(batch_size, num_epochs, rate, name))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "\n",
    "eegclassifier1_1 = CNN_EEG_Classifier_3cnn_medium_kernel()\n",
    "eegclassifier1_2 = CNN_EEG_Classifier_3cnn_medium_kernel()\n",
    "eegclassifier1_3 = CNN_EEG_Classifier_3cnn_medium_kernel()\n",
    "\n",
    "eegclassifier2_1 = CNN_EEG_Classifier_3cnn_medium_kernel_leaky()\n",
    "eegclassifier2_2 = CNN_EEG_Classifier_3cnn_medium_kernel_leaky()\n",
    "eegclassifier2_3 = CNN_EEG_Classifier_3cnn_medium_kernel_leaky()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_adam_ce' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mB.Homes$\\bhutanig\\Documents\\EEG-Alzheimer-Detection\\lstm_test_remote.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell://vsrv1/B.Homes%24/bhutanig/Documents/EEG-Alzheimer-Detection/lstm_test_remote.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_adam_ce(eegclassifier1_1, batch_size \u001b[39m=\u001b[39m \u001b[39m127\u001b[39m, num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, rate \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m, name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCNN_EEG_Classifier_3cnn_medium_kernel train_adam_ce\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell://vsrv1/B.Homes%24/bhutanig/Documents/EEG-Alzheimer-Detection/lstm_test_remote.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest accuracy:\u001b[39m\u001b[39m\"\u001b[39m,get_accuracy(eegclassifier1_1, train \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, train_data \u001b[39m=\u001b[39m testloader))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_adam_ce' is not defined"
     ]
    }
   ],
   "source": [
    "train_adam_ce(eegclassifier1_1, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel train_adam_ce\")\n",
    "print(\"Test accuracy:\",get_accuracy(eegclassifier1_1, train = True, train_data = testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adam_ce_step_lr(eegclassifier1_2, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel train_adam_ce_step_lr\")\n",
    "print(\"Test accuracy:\",get_accuracy(eegclassifier1_2, train = True, train_data = testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adam_ce_lin_lr(eegclassifier1_3, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel train_adam_ce_lin_lr\")\n",
    "print(\"Test accuracy:\",get_accuracy(eegclassifier1_3, train = True, train_data = testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adam_ce_step_lr(eegclassifier2_1, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel_leaky train_adam_ce_step_lr\")\n",
    "print(\"Test accuracy:\",get_accuracy(eegclassifier2_1, train = True, train_data = testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adam_ce(eegclassifier2_2, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel_leaky train_adam_ce\")\n",
    "print(\"Test accuracy:\",get_accuracy(eegclassifier2_2, train = True, train_data = testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adam_ce_lin_lr(eegclassifier2_3, batch_size = 127, num_epochs = 10, rate = 0.1, name = \"CNN_EEG_Classifier_3cnn_medium_kernel_leaky train_adam_ce_lin_lr\")\n",
    "print(\"Test accuracy:\",get_accuracy(eegclassifier2_3, train = True, train_data = testloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
